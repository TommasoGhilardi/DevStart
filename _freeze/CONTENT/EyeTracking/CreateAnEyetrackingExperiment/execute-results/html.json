{
  "hash": "2d6bd2f51b10cd4505270e322ba08a9e",
  "result": {
    "markdown": "---\ntitle: Create an eye-tracking experiment\nexecute:\n  eval: false\n\npagetitle: Create an eye-tracking experiment\nauthor-meta: Tommaso Ghilardi\ndescription-meta: Learn how to record eyetracking data in your psychopy experiment using Tobii SDK and psychopy_tobii_infant.\nkeywords: PsychoPy, Python, eye-tracking, psychopy_tobii_infant, tobii, experimental psychology, tutorial, experiment, DevStart, developmental science\n---\n\nThis page will show you how to collect eye-tracking data in a simple psychopy paradigm. We will use the same paradigm that we built together in the [Getting started with Psychopy](GettingStartedWithPsychopy.qmd) tutorial. If you have not done that tutorial yet, please go through it first.\n\n::: callout-caution\n## Tobii eye-tracker\n\nNote that this tutorial is specific for using **Tobii eye-trackers**. The general steps and idea are obviously applicable to other eye-trackers, but the specific code and packages vary depending on the device.\n:::\n\n## How to connect to the eye-tracker\n\nWe have different options to use our Tobii eye tracker. One option is to use the software that Tobii provides. However, this software is very expensive and sometimes not flexible enough for all the studies. We prefer to use the **SDK** that Tobii provides.\n\nAn **SDK** is a collection of tools and programs for developing applications for a specific platform or device. We will use the **Python Tobii SDK** that lets us easily find and get data from our Tobii eye tracker.\n\nTo install the Python Tobii SDK, we can run this command:\n\n``` bash\npip install tobii_research\n```\n\nGreat! We have installed the Tobii SDK. However, using the SDK is not very easy. But don't worry! We have a solution for you. We can use [Psychopy_tobii_infant](https://github.com/yh-luo/psychopy_tobii_infant), a wrapper around the Tobii SDK that is specially designed for running infant-friendly studies. This code collection allows us to use the Tobii SDK with the Psychopy interface.\n\nTo use Psychopy_tobii_infant, you need to go to this GitHub page: <https://github.com/yh-luo/psychopy_tobii_infant>. On this page, you can click on ***\\<\\>Code*** and then on ***Download ZIP*** as shown below:\n\n![](images/CreateAnEyetrackingExperiment/DowloadPsychopyTobiiInfant.jpg){fig-align=\"center\" width=\"545\"}\n\nPerfect!! Now that we have downloaded the code as a zip file we need to:\n\n-   extract the file\n\n-   identify the folder *'psychopy_tobii_infant'*\n\n-   copy this folder in the same location of your eye-tracking experiment script\n\nYou should end up like with something like this:\\\n![](images/CreateAnEyetrackingExperiment/FinalConfTobiiInfant.png)\n\n**Now we are all set and ready to go !!!!!!!!!!**\n\n## Short recap of the paradigm\n\nAs we alredy mentioned, we will use the experiemntal dsign that we created in [Getting started with Psychopy](GettingStartedWithPsychopy.qmd) as a base and we will add things to it to make it an eye-tracking study. Before getting started, let's review the design.\n\nAfter a fixation cross two shapes can be presented: a circle or a square. The circle indicates that a reward will appear on the right of the screen while the square predicts the appearance of an empty cloud on the left.\n\n![](images/GettingStartedWithPsychopy/Design.jpg){fig-align=\"center\"}\n\nHere the code we wrote together to build this design.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Import some libraries from PsychoPy\nfrom psychopy import visual\nfrom psychopy import core\nfrom psychopy import sound\n\n# Let's define the path we will work with.\n# in my case the stimuli that we will use are in here but you will have to adapt\n# this variable to where you have downloaded the stimuli.\nPath = r'C:\\\\Users\\\\tomma\\\\surfdrive - Ghilardi, T. (Tommaso)@surfdrive.surf.nl\\\\Documentation\\\\Working\\\\GettingStartedWithPsychopy\\\\'\n\n# create a window\nwin = visual.Window(fullscr = True, units=\"pix\")\n\n# Load images\nfixation = visual.ImageStim(win, image=Path + 'fixation.png', size = (100, 100))\ncircle   = visual.ImageStim(win, image=Path + 'circle.png', size = (100, 100))\nsquare   = visual.ImageStim(win, image=Path + 'square.png', size = (100, 100))\nwinning   = visual.ImageStim(win, image=Path + 'winning.png', size = (100, 100), pos=(600,0))\nloosing  = visual.ImageStim(win, image=Path + 'loosing.png', size = (100, 100), pos=(-600,0))\n\n# Load sound\nwinning_sound = sound.Sound(Path + 'winning.wav')\nlosing_sound = sound.Sound(Path + 'loosing.wav')\n\n# List of stimuli\ncues = [circle, square] # put both cues in a list\nrewards = [winning, loosing] # put both rewards in a list\nsounds = [winning_sound,losing_sound] # put both sounds in a list\n\n\n# Create list of trials in which 0 means winning and 1 means losing\nTrials = [0, 1, 0, 0, 1, 0, 1, 1, 0, 1 ]\n\n\nfor trial in Trials:\n\n    ### Present the fixation\n    win.flip() # we flip to clean the window\n\n    fixation.draw()\n    win.flip()\n    core.wait(1)  # wait for 1 second\n\n\n    ### Present the cue\n    cues[trial].draw()\n    win.flip()\n    core.wait(3)  # wait for 3 seconds\n\n\n    ### Present the reward\n    rewards[trial].draw()\n    win.flip()\n    sounds[trial].play()\n    core.wait(2)  # wait for 1 second\n    win.flip()    # we re-flip at the end to clean the window\n\n    ### ISI\n    core.wait(0.3) # add Inter Stimulus Interval to make exp more understandable\n\nwin.close()\n```\n:::\n\n\n",
    "supporting": [
      "CreateAnEyetrackingExperiment_files"
    ],
    "filters": [],
    "includes": {}
  }
}