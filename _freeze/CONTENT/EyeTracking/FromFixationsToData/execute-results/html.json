{
  "hash": "884be1c60058c498601efe7a7847964b",
  "result": {
    "markdown": "---\ntitle: \"From fixations to data\"\nexecute:\n  eval: false\n\npagetitle: From fixations to data\nauthor-meta: Tommaso Ghilardi\ndescription-meta: Learn how to extract different eye-tracking measures from the collected data\nkeywords: Python, saccadic-latency, looking time, eye-tracking, tobii, experimental psychology, tutorial, experiment, DevStart, developmental science\n---\n\nIn the previous two tutorial we [collected some eye-trackign data](CreateAnEyetrackingExperiment.qmd) and then we have [used I2MC to extract the fixations](I2MC_tutorial.qmd) from that data. That is a good first step but what can we do with fixations? Not much I am afraid. But we can use these fixation to extract some more meaningful indexes.\n\nIn this tutorial we will look at how to extract two features from our paradigm.\n\n-   **Saccadic latency:** how quickly our participant looked at the correct location. This includes checking whether the participant was able to anticipate the appearance of the stimulus. In our paradigm we will look at how fast our participant looked at the target location (left: NoReward, right: Reward).\n\n-   **Looking time:** how long our participant looked at certain locations on the screen. In our case we will look at how long our participant looked at the two target locations (left: NoReward, right: Reward).\n\nSo what do these two measures have in common? EXACTLY!!! They are both clearly related to the position of our stimuli. It is indeed important to define our Areas Of Interest (AOI), where we will check whether our participant was looking into.\n\n# AOIs\n\n## Define AOIs\n\nAs AOIs are important, let's define them. We will define two squares around the target positions. To do this we can simply pass two coordinates for each AOI: the lower left corner and the upper right corner.\n\nAn important point to understand is that tobii and psychopy use two different coordinate systems:\n\n-   Psychopy has it's origin (0,0) in the centre of the window/screen by default.\n\n-   Tobii reports data with it's origin (0,0) in the lower left corner.\n\nThis inconsistency is not a problem per se, but we obviously need to take it into account when defining the AOIs. Let's try to define the AOIs:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Define the variable realted to the screen and to the target position\nscreensize = (1920, 1080)\ndimension_of_AOI = 600/2\nTarget_position = 500\n\n# Create areas of interest\nAOI1 =[[screensize[0]/2 - Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 - Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n\nAOI2 =[[screensize[0]/2 + Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 + Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n\nAOIs = [AOI1, AOI2]\n```\n:::\n\n\nNice!! This step is essential. We have created two AOIs. We will use them to define whether the gaze of our participant was on these two AOIs. Let's get a better idea by just plotting these two AOIs and two random points `(600, 500)` and `(1400,1000)`.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Create a figure\nfig, ax = plt.subplots(1)\n\n# Set the limits of the plot\nax.set_xlim(0, 1920)\nax.set_ylim(0, 1080)\n\n# Define the colors for the rectangles\ncolors = ['#46AEB9', '#C7D629']\n\n# Create a rectangle for each area of interest and add it to the plot\nfor i, (bottom_left, top_right) in enumerate(AOIs):\n    width = top_right[0] - bottom_left[0]\n    height = top_right[1] - bottom_left[1]\n    rectangle = patches.Rectangle(bottom_left, width, height, linewidth=2, edgecolor='k', facecolor=colors[i])\n    ax.add_patch(rectangle)\n\nax.plot(600,500,marker='o', markersize=8, color='green')    \nax.plot(1400,1000,marker='o', markersize=8, color='red')    \n\n# Show the plot\nplt.show()\n```\n:::\n\n\n## Points in AOIs\n\nAs you can see we are plotting the two AOIs and two points. One falls into one of it and the second doesn't. But how can we get python to tell us if a point is falling inside one of our AOIs? We can write a simple function to check that.\n\n",
    "supporting": [
      "FromFixationsToData_files"
    ],
    "filters": [],
    "includes": {}
  }
}