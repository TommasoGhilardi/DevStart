{
  "hash": "d36831647f6553981d8f4e3342f17256",
  "result": {
    "markdown": "---\ntitle: \"From fixations to measures\"\nexecute:\n  eval: false\n\nauthor-meta: Tommaso Ghilardi\ndescription-meta: \"Learn how to extract different eye-tracking measures from the collected data\"\nkeywords: \"Python, latency, saccadic-latency, looking time, eye-tracking, tobii, experimental psychology, tutorial, experiment, DevStart, developmental science\"\n---\n\nIn the previous two tutorials we [collected some eye-tracking data](CreateAnEyetrackingExperiment.qmd) and then we [used I2MC to extract the fixations](I2MC_tutorial.qmd) from that data. Let's load the data we recorded and pre-processed in the previous tutorial. We will import some libraries and read the raw data and the output from I2MC.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n#%% Settings\n\n# # Settign the working directory\nos.chdir(r'C:\\Users\\tomma\\OneDrive - Birkbeck, University of London\\TomassoGhilardi\\PersonalProj\\BCCCD')\n\n# Screen resolution\nres = [1920, 1080]\n\n\n#%% Read and prepare data\n\n# The fixation data extracted from I2MC\nFixations = pd.read_csv('Data\\\\i2mc_output\\\\Test1\\Test1.csv')\n\n# The original RAW data\nRaw_data = pd.read_csv('Data\\\\RAW\\\\Test1.csv')\n\n# Start Recording from 0 and in Seconds\nRaw_data['time'] = Raw_data['time'] - Raw_data.loc[0,'time']\n```\n:::\n\n\nWhat can we do with just the raw data and the fixations? Not much I am afraid. But we can use these fixations to extract some more meaningful indexes.\n\nIn this tutorial, we will look at how to extract two variables from our paradigm:\n\n-   **Saccadic latency:** how quickly our participant looked at the correct location. This includes checking whether the participant could anticipate the stimulus appearance. In our paradigm, we will look at how fast our participant looked at the target location (left: NoReward, right: Reward).\n\n-   **Looking time:** how long our participant looked at certain locations on the screen. In our case, we will look at how long our participant looked at either target location (left: NoReward, right: Reward) on each trial.\n\nSo what do these two measures have in common? *pregnant pause for you to answer* EXACTLY!!! They are both clearly related to the position of our stimuli. For this reason, it is important to define Areas Of Interest (AOIs) on the screen (for example, the locations of the targets). Defining AOIs will allow us to check, for each single fixation, whether it happened in an area that we are interested in.\n\n# Areas Of Interest\n\n## Define AOIs\n\nLet's define AOIs. We will define two squares around the target locations. To do this, we can simply pass two coordinates for each AOI: the lower left corner and the upper right corner of an imaginary square.\n\nAn important point to understand is that tobii and Psychopy use two different coordinate systems:\n\n-   Psychopy has its origin (0,0) in the centre of the window/screen by default.\n\n-   Tobii reports data with its origin (0,0) in the lower left corner.\n\nThis inconsistency is not a problem per se, but we need to take it into account when defining the AOIs. Let's try to define the AOIs:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Define the variable realted to the screen and to the target position\nscreensize = (1920, 1080) \ndimension_of_AOI = 600/2  #the dimension of the AOIs, divided by 2\nTarget_position = 500 #the position of the targets relative to the centre (e.g., 500 pixels on the right from the centre)\n\n# Create areas of interest\nAOI1 =[[screensize[0]/2 - Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 - Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n\nAOI2 =[[screensize[0]/2 + Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 + Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n\nAOIs = [AOI1, AOI2]\n```\n:::\n\n\nNice!! This step is essential. We have created two AOIs. We will use them to define whether each fixation of our participant was within either of these two AOIs. Let's get a better idea by just plotting these two AOIs and two random points `(600, 500)` and `(1400,1000)`.\n\n::: {.cell fig-height='1080' fig-width='1920' execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Create a figure\nfig, ax = plt.subplots(1)\n\n# Set the limits of the plot\nax.set_xlim(0, 1920)\nax.set_ylim(0, 1080)\n\n# Define the colors for the rectangles\ncolors = ['#46AEB9', '#C7D629']\n\n# Create a rectangle for each area of interest and add it to the plot\nfor i, (bottom_left, top_right) in enumerate(AOIs):\n    width = top_right[0] - bottom_left[0]\n    height = top_right[1] - bottom_left[1]\n    rectangle = patches.Rectangle(bottom_left, width, height, linewidth=2, edgecolor='k', facecolor=colors[i])\n    ax.add_patch(rectangle)\n\nax.plot(600,500,marker='o', markersize=8, color='green')    \nax.plot(1400,1000,marker='o', markersize=8, color='red')    \n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](FromFixationsToData_files/figure-html/cell-4-output-1.png){fig-align='center'}\n:::\n:::\n\n\n## Points in AOIs\n\nAs you can see, we are plotting the two AOIs and two points. One falls into one of them and the other doesn't. But how can we get Python to tell us if a point falls within one of our AOIs?\n\nWe can check whether the (x, y) coordinates of the point are within the x and y coordinates of the left bottom and top right corners of the AOI. So imagine we have a point: `point` and an area: `area`, we can check if the point falls inside the area by:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Extract bottom left and top right points\nbottom_left, top_right = area\n\n# Extract the x and y of each point\nbottom_X, bottom_y = bottom_left\ntop_x, top_y = top_right\n\n# Extract the x and y of our point of interest\nx, y = point\n\n# Check if the point is in the area\nbottom_x <= x <= top_x and bottom_y <= y <= top_y\n```\n:::\n\n\nPerfect, this will return True if the point falls inside the area and False if it falls outside. Since we have two AOIs and not just one, we want to make things a bit fancier. We will create a function that checks if a point falls within a list of areas, and tells us which area it falls in.\n\nWe will run the code above in a loop using `enumerate`. This extracts two elements to our loop: the index of the element and the element itself. In our case the index of the area and the area itself. This is very useful as we can then use both of these two pieces of information. We will use the actual area to check if our points fall into it. Then, if it does, we will return the index of that area. Conversely, if the point doesn't fall in any area the function will return -1.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# We define a function that simply takes the a point and a list of areas.\n# This function checks in which area this point is and return the index\n# of the area. If the point is in no area it returns -1\ndef find_area_for_point(point, areas):\n\n    for i, area in enumerate(areas):\n        # Extract bottom left and top right points\n        bottom_left, top_right = area\n        \n        # Extract the x and y of each point\n        bottom_X, bottom_y = bottom_left\n        top_x, top_y = top_right\n        \n        # Extract the x and y of our point of interest\n        x, y = point\n        \n        # Check if the point is in the area\n        bottom_x <= x <= top_x and bottom_y <= y <= top_y :\n            return(i)\n    return(-1)\n```\n:::\n\n\nNow we have a cool function to check whether a point falls into any of our AOIs. We can use this function to filter the fixations that are in the AOIs: These are the only ones we care about.\n\n# Time Of Interest\n\nNow that we've figured out how to select fixations that fall within our areas of interest, it's time to consider another important factor: Time. Our experiment involves presenting a variety of stimuli, including fixation crosses, cues, and rewards. However, we're not interested in analyzing the entire experiment. Instead, we focus on specific events.\n\nIn this case, our attention is on the target window. We're going to establish a time window that begins 750ms before the target appears and continues for 2000ms after its presentation. Indeed, both **Saccadic latency** and **Lookign time** occur within this time window, while we don't really care about where the participant is looking during other phases of the task.\n\nLet's start by finding the moment in which the target appeared:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Let's find the time we presented a reward or no reward\nTargets = Raw_data.loc[(Raw_data['Event'] == 'Reward') | (Raw_data['Event'] == 'NoReward'), ['time', 'Event']].values\n```\n:::\n\n\nHaving identified the moments when the targets were presented, we can now establish a time window around each of these instances. To accomplish this, we will iterate over the identified times and select all the fixations that occur within the defined window. To make things clearer, we're going to add two new columns to our fixation dataframe: `Event` and `Event_trial`. These will help us know which event each fixation is linked to and which specific trial it belongs to. Plus, we're going to add another column called `Onset` to the fixations dataframe. This will let us store the onset times of specific events, making our analysis down the line a whole lot simpler.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Find the fixations that we care about\npre  = -750\npost = 400\n\nfor i,c in enumerate(Targets):\n    \n    # Find which row meets our conditions\n    mask = (Fixations['startT'] >= c[0]+pre) & (Fixations['startT'] < c[0]+post)\n    \n    # Fill the rows with have found with more info\n    Fixations.loc[mask, 'Event'] = c[1]\n    Fixations.loc[mask, 'Event_trial'] = i\n    Fixations.loc[mask, 'Onset'] =  c[0]\n```\n:::\n\n\nOur Fixations dataframe is now chock-full of event-related info. But, there's a catch. The fixations that took place at times other than during the target presentation are still hanging around in the dataframe. And they're filled with NANs in the new columns we just created. We can use this to our advantage and filter all the NANs out:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# We can drop the NANs to have only the fixations that interest us!!!!\nTarget_fixations = Fixations[Fixations['Event'].notna()].reset_index(drop = True)\n```\n:::\n\n\n# Put things together\n\nNow we have selected our fixations based on the events. But we also need to filter the fixations based on the AOIs. If only we had some functions to do so.... Oh wait we actually just created them!! Let's make use of them!!\n\nAs a first step, we will add a new column to our Target_fixations dataframe containing the AOIs we defined together before. Thus, each row of this column will tell us which AOIs we should check. We will also add a new column called `Looked_AOI` where we will storethe indexes of which AOI the fixation fell into.\n\n::: callout-important\nJust a heads up, our study design is pretty straightforward with only two stable Areas of Interest (AOIs). But if you're dealing with multiple or moving AOIs, you've got options. You can add them to each row of the dataframe, depending on the event or trial. This way, you get more control over which area to inspect at any given moment of the study. It's all about flexibility and precision!\n:::\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nTarget_fixations['AOIs'] = [AOIs]* len(Latency_fixations)\nTarget_fixations['Looked_AOI'] = np.NAN\n```\n:::\n\n\nNow that we have a columns with the AOIs in our Target_fixations dataframe we can run our function `find_area_for_point()` to check in which AOI each fixation falls into.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# We run the function  for each row. We pass each xpos and ypos to the function\n# toghether with the areas\nfor row in range(len(Target_fixations)):\n    \n    Point = Target_fixations.loc[row, ['xpos', 'ypos']].values\n    Areas = Target_fixations.loc[row, 'AOIs']\n    \n    Target_fixations.loc[row, 'Looked_AOI'] = find_area_for_point(Point, Areas)\n```\n:::\n\n\nPerfect, we now have a dataframe that contains only the fixations of interest and tells us which AOI each fixation is in. Before we continue, let's remove the fixations that didn't fall in any AOI (if you remember or the function assigns -1 if the fixation is outside any AOI):\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# Filter for AOI of interest\nTarget_fixations = Target_fixations[Target_fixations['Looked_AOI'] != -1]\n```\n:::\n\n\n# Saccadic latency\n\nAs I mentioned at the beginning of this tutorial, one of the indices we want to extract is saccadic latency. Basically, how quickly our participants fixated on the target location.\n\nIf we know where our participant was supposed to look, we can easily find the first fixations. Sounds simple, right?\n\nOur paradigm was very simple, every time the non rewarding stimulus was presented on the left (the first AOI we defined) and the rewarding stimulus was presented on the right (the second AOI we defined). Thus we can add this information to our dataframe and then use it to filter our the wrong fixations:\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# We define which is the correct AOI that the participant should have looked.\nTarget_fixations.loc[Target_fixations['Event'] == 'NoReward', 'Correct_Aoi'] = 0\nTarget_fixations.loc[Target_fixations['Event'] == 'Reward'  , 'Correct_Aoi'] = 1\n\n# We select only the correct fixations\nCorrect_Target_fixations = Target_fixations[Target_fixations['Correct_Aoi'] == Target_fixations['Looked_AOI']]\n```\n:::\n\n\nNow we can finally extract the saccadic latency by simply subtracting the from the onset of the fixations (`startT`) the onset of the event `Onset`:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nCorrect_Target_fixations['Latency'] = Correct_Target_fixations['Onset'] - Correct_Target_fixations['startT']\n```\n:::\n\n\nVoilÃ¡!! as simple as this!!! Now our `Latency` column will contain the onset of the fixations in relation to the target presentation.\n\n::: callout-note\nSaccadic latency can be negative!!. This indicates that participants were able to predict the location of the stimulus and directed their gaze to it in anticipation. Typically, this is the primary use of saccadic latency - it serves as a tool to assess participants' expectations in relation to our design.\n:::\n\n## First fixation\n\nWe have all these latency values, but we only want the first/fastest of each trial. How can we extract this information easily? We will use groupby. Groupby allows us to perform specific functions/commands on grouped sections of a data frame.\n\nHere we will groupby by Events and Event_trials and for each of these grouped pieces of dataframe we will extract the smallest (`min()`) value of latency.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# We extract the first fixation of our dataframe for each event\nSaccadicLatency = Correct_Target_fixations.groupby(['Event', 'Event_trial'])['Latency'].min().reset_index()\n```\n:::\n\n\nHere we have our **Saccadic latency**!!!\n\n# Looking time\n\nWhile our paradigm was designed with saccadic latency in mind, for the purposes of this tutorial we will also be looking at the extraction of looking time. Looking time is a measure that tell us how much our participant was looking in either of the two AOIs at each trial.\n\nWe have already extracted all the information we need, we just need to do the final steps. We will again use groupby to group our dataframe by `Event`, `Event_trial` and `Looked_AOI`. For each of the grouped dataframes we will extract the `sum()` of each fixation duration. This will tell us how much the participant looked at each of the two AOIs for each trial.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Using groupby we can extrac the sum of the duration of the fixation for each reward and trial\nLookingTime = Target_fixations.groupby(['Event', 'Event_trial', 'Looked_AOI'], as_index=False)['dur'].sum()\n```\n:::\n\n\n# END!!\n\nWell done!! we have successfully extract both Saccadic latency and Lookign time from our data. Remember that is is just a simple tutorial based on an even simpler design. However if you got to teh end nad you have understood all the steps and what they mean I am sure you can apply this knowledge to your study as well. If you have any question or somethign is not clear feel free to send us an email!!\\\n\\\nHere below the entire script!!\\\n\n``` python\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n\n#%% Fucntions\n\n# We define a function that simply takes the a point and a list of areas.\n# This function checks in which area this point is and return the index\n# of the area. If the point is in no area it returns -1\ndef find_area_for_point(point, areas):\n\n    for i, area in enumerate(areas):\n        # Extract bottom left and top right points\n        bottom_left, top_right = area\n        \n        # Extract the x and y of each point\n        bottom_X, bottom_y = bottom_left\n        top_x, top_y = top_right\n        \n        # Extract the x and y of our point of interest\n        x, y = point\n        \n        # Check if the point is in the area\n        bottom_x <= x <= top_x and bottom_y <= y <= top_y :\n            return(i)\n    return(-1)\n\n\n\n#%% Settings and reading data\n\n# Settign the working directory\nos.chdir(r'C:\\Users\\tomma\\OneDrive - Birkbeck, University of London\\TomassoGhilardi\\PersonalProj\\BCCCD')\n\n# Screen resolution\nres = [1920, 1080]\n\n# The fixation data extracted from I2MC\nFixations = pd.read_csv('Data\\\\i2mc_output\\\\Test1\\Test1.csv')\n\n# The original RAW data\nRaw_data = pd.read_csv('Data\\\\RAW\\\\Test1.csv')\n\n# Start Recording from 0 and in Seconds\nRaw_data['time'] = Raw_data['time'] - Raw_data.loc[0,'time']\n\n\n\n#%% Time of interest\n\n# Let's find the time we presented a reward or no reward\nTargets = Raw_data.loc[(Raw_data['Event'] == 'Reward') | (Raw_data['Event'] == 'NoReward'), ['time', 'Event']].values\n\n# Find the fixations that we care about\npre  = -750\npost = 400\n\nfor i,c in enumerate(Targets):\n    \n    # Find which row meet our conditions\n    mask = (Fixations['startT'] >= c[0]+pre) & (Fixations['startT'] < c[0]+post)\n    \n    # Fill the rows with have found with more info\n    Fixations.loc[mask, 'Event'] = c[1]\n    Fixations.loc[mask, 'Event_trial'] = i\n    Fixations.loc[mask, 'Onset'] =  c[0]\n    \n# We can drop the NANs to have only the fixations that interest us!!!!\nTarget_fixations = Fixations[Fixations['Event'].notna()].reset_index(drop = True)\n\n\n\n#%% Put things toghether\n\n# Add the AOIs to dataframe\nTarget_fixations['AOIs'] = [AOIs]* len(Latency_fixations)\nTarget_fixations['Looked_AOI'] = np.NAN\n\n# We run the function  for each row. We pass each xpos and ypos to the function\n# toghether with the areas\nfor row in range(len(Target_fixations)):\n    \n    Point = Target_fixations.loc[row, ['xpos', 'ypos']].values\n    Areas = Target_fixations.loc[row, 'AOIs']\n    \n    Target_fixations.loc[row, 'Looked_AOI'] = find_area_for_point(Point, Areas)\n    \n# Filter for AOI of interest\nTarget_fixations = Target_fixations[Target_fixations['Looked_AOI'] != -1]\n\n\n\n#%% Saccadic Latency\n\n# We define which is the correct AOI that the participant should have looked.\nTarget_fixations.loc[Target_fixations['Event'] == 'NoReward', 'Correct_Aoi'] = 0\nTarget_fixations.loc[Target_fixations['Event'] == 'Reward'  , 'Correct_Aoi'] = 1\n\n# We select only the correct fixations\nCorrect_Target_fixations = Target_fixations[Target_fixations['Correct_Aoi'] == Target_fixations['Looked_AOI']]\n\n# Keep only the fixation to the correct AOI\nCorrect_Target_fixations['Latency'] = Correct_Target_fixations['Onset'] - Correct_Target_fixations['startT']\n\n# We extract the first fixation of our dataframe for each event\nSaccadicLatency = Correct_Target_fixations.groupby(['Event', 'Event_trial'])['Latency'].min().reset_index()\n\n\n\n#%% Looking time\n\n# Using groupby we can extrac the sum of the duration of the fixation for each reward and trial\nLookingTime = Target_fixations.groupby(['Event', 'Event_trial', 'Looked_AOI'], as_index=False)['dur'].sum()\n```\n\n",
    "supporting": [
      "FromFixationsToData_files"
    ],
    "filters": [],
    "includes": {}
  }
}