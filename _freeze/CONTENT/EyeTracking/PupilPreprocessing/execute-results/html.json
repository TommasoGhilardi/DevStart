{
  "hash": "c8868bfdb6cec39939a6a0f0989e045c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Pupil data pre-processing \"\ndate: \"12/18/2024\"\n\nauthor-meta: \"Tommaso Ghilardi\"\ndescription-meta: \"Learn the fundamentals of pupil dilation processing using PupillometryR\"\nkeywords: \"pupil dilation, pupillometry, eye-tracking, experiments, infant research, DevStart, developmental science\"\ncategories:\n  - Pupillometry\n  - R\n  - Pre-processing\nlightbox: true\n---\n\n\n\n\nWelcome to your first step into the world of pupillometry! In this tutorial, we‚Äôll walk you through how to preprocess pupil data using a handy R package called [PupillometryR](http://samforbes.me/PupillometryR/index.html). This package makes it simple to clean and even analyze your pupil data with just a few lines of R code.\n\nTo keep things straightforward, we‚Äôll be working with a simulated dataset that you can download right here:\n\n\n\n\n{{< downloadthis ../../resources/Pupillometry/RAW/PupilData.zip label=\"PupilData.zip\" dname= \"Raw data\" type=\"secondary\" >}}\n\n\n\n\n\n\nDownload and unzip this folder. This dataset is based on the experimental design we introduced earlier in our eye-tracking series. If you‚Äôre not familiar with it or need a quick refresher, we recommend checking out the \"[Introduction to eye-tracking](Intro_eyetracking.qmd)\" guide before diving in.\n\nThis tutorial serves as a foundation for understanding how to preprocess pupil data. Once you've grasped the essentials, we encourage you to explore the full range of functions and features [PupillometryR](http://samforbes.me/PupillometryR) has to offer.\n\n::: callout-note\nIn this and upcoming tutorials, we‚Äôll use **dplyr**, a package included in the **tidyverse** collection. **dplyr** is designed for efficient manipulation of dataframes and makes it easy to perform operations using the **Magrittr pipe (`%>%`)**. This pipe allows you to chain multiple operations on a dataframe in a seamless flow, avoiding intermediate steps or temporary variables.\n\nWe‚Äôll focus on basic **dplyr** functions for now, including:\n\n-   **`filter()`**: Used to subset rows based on specific conditions.\\\n    *Example*: Keep rows where `data %>% filter( Event == \"Circle\")`.\n\n-    **`mutate()`**: Adds or modifies columns in the dataframe.\\\n    *Example*: Create a new column `data %>% mutate(mean_pupil_norm = mean_pupil / 100)`.\n\n-    **`group_by()`**: Groups the dataframe by one or more columns for grouped operations.\\\n    *Example*: Group data by `data %>% group_by(Subject, Event)`.\n\n-    **`summarize()`**: Aggregates data within groups to compute summary statistics.\\\n    *Example*: Calculate the mean pupil size for each group.\n\n**Basic Syntax**\n\nThe syntax begins by passing a dataframe into the pipe (`%>%`) and then applying one or more operations. These functions directly manipulate the dataframe without requiring it (or its columns) to be explicitly referenced in each step.\n\nHere‚Äôs an example:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata2 = data %>%\n    filter(Events == \"Circle\") %>%\n    group_by(Subject) %>%\n    summarize(mean_pupil = mean(mean_pupil, na.rm = TRUE)) \n```\n:::\n\n\n\n\nThis code filters rows where `Events == \"Circle\"`, groups data by `Subject`, and calculates the mean pupil size for each subject, creating a new dataframe, `data2`, in a concise and readable flow. üöÄ\n\nThis is just the tip of the iceberg ‚ùÑÔ∏è‚Äî**dplyr** is an incredible tool! If you want to explore its full potential, check out this tutorial: [R dplyr Tutorial \\| Learn with Examples](https://sparkbyexamples.com/r-programming/r-dplyr-tutorial-learn-with-examples/)\n:::\n\n## Read the data\n\nLet's begin by importing the necessary libraries and loading the downloaded dataframe.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nGreat! Now, let‚Äôs locate and load all our data files. We‚Äôll use `list.files()` to identify all the `.csv` files in our folder. Make sure to update the file path to match the location where your data is stored.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncsv_files = list.files(\n  path       = \"..\\\\..\\\\resources\\\\Pupillometry\\\\RAW\",\n  pattern    = \"\\\\.csv$\",   # regex pattern to match .csv files\n  full.names = TRUE         # returns the full file paths\n)\n```\n:::\n\n\n\n\n`csv_files` is now a list containing all the `.csv` files we‚Äôve identified. To better understand our dataset, let‚Äôs start by focusing on the first file, representing the first subject, and inspect its structure. This will give us a clear overview before we proceed further.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRaw_data = read.csv(csv_files[1])\nhead(Raw_data) # database peak\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  X   Subject      time      L_P      R_P    Event TrialN\n1 1 Subject_1  1.000000 3.187428 3.228510 Fixation      1\n2 2 Subject_1  4.333526 3.153315 3.193957     <NA>     NA\n3 3 Subject_1  7.667052 3.102050 3.142032     <NA>     NA\n4 4 Subject_1 11.000578 3.163670 3.204446     <NA>     NA\n5 5 Subject_1 14.334104 3.152682 3.193316     <NA>     NA\n6 6 Subject_1 17.667630 3.086508 3.126289     <NA>     NA\n```\n\n\n:::\n:::\n\n\n\n\nOur dataframe consists of several easily interpretable columns. **time** represents elapsed time in milliseconds, **Subject** identifies the participant, and **Event** indicates when and which stimuli were presented. **TrialN** tracks the trial number, while **L_P** and **R_P** measure pupil dilation for the left and right eyes, respectively, in millimeters.\n\nLet's plot the data! Visualizing it first is always a crucial step as it provides an initial understanding of its structure and key patterns.\n\n\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\nggplot(Raw_data, aes(x = time, y = R_P)) +\n  geom_line(aes(y = R_P, color = 'Pupil Right'), lwd = 1.2) +\n  geom_line(aes(y = L_P, color = 'Pupil Left'), lwd = 1.2) +\n  geom_vline(data = Raw_data |> dplyr::filter(!is.na(Event)), aes(xintercept = time, linetype = Event), lwd = 1.3) +\n  \n  theme_bw(base_size = 35) +\n  ylim(1, 6) +\n  labs(color= 'Signal', y='Pupil size')+\n  scale_color_manual(\n    values = c('Pupil Right' = '#4A6274', 'Pupil Left' = '#E2725A') )  +\n  theme(\n    legend.position = 'bottom'  ) +\n  guides(\n    color = guide_legend(override.aes = list(lwd = 20)),\n    linetype = guide_legend(override.aes = list(lwd = 1.2))\n  )\n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/PlotRaw-1.png){width=1920}\n:::\n:::\n\n\n\n\n## Prepare the data\n\nNice!! Now we have some sense of our data!! And....you‚Äôve probably noticed two things:\n\n1.  **So many events!** That‚Äôs intentional ‚Äî it‚Äôs better to have too many triggers than miss something important. When we recorded the data, we saved all possible events to ensure nothing was overlooked. But don‚Äôt worry, for our pupil dilation analysis, we only care about two key events: **Circle** and **Square** (check the [paradigm intro](CreateAnEyetrackingExperiment.qmd) if you need a refresher on why this is)\n\n2.  **Single-sample events!** Like in most studies, events are marked at a single time point (when the stimulus is presented). But PupilometryR needs a different structure ‚Äî it expects the event value to be repeated for every row while the event is happening.\n\nSo, how do we fix this? First, let‚Äôs isolate the rows in our dataframe where the events are **Circle** or **Square**. We start by creating a list of the events we care about, then use it to filter our dataframe and keep only the rows related to those events in a new dataframe called Events\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nEvents_to_keep = c('Circle','Square')\nEvents = filter(Raw_data, Event %in% Events_to_keep) # filter data\nhead(Events) # database peak\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      X   Subject       time      L_P      R_P  Event TrialN\n1   221 Subject_1   734.3757       NA       NA Circle      1\n2  2552 Subject_1  8504.8248 3.596057 3.642405 Square      2\n3  4883 Subject_1 16275.2739 3.543367       NA Circle      3\n4  7215 Subject_1 24049.0565 3.164419 3.205205 Circle      4\n5  9546 Subject_1 31819.5055 3.147494 3.188061 Square      5\n6 11877 Subject_1 39589.9546 3.343493 3.386587 Circle      6\n```\n\n\n:::\n:::\n\n\n\n\nPerfect! Now onto the second point: we need to repeat the events we just selected for the entire duration we want to analyze. But what‚Äôs this duration? We want to cover the full cue presentation (2 seconds), plus an extra 0.1 seconds before the stimulus appears. Why? This pre-stimulus period will serve as our baseline, which we‚Äôll use later in the analysis.\n\nSo, let‚Äôs define how much time to include before and after the stimulus. We‚Äôll also set the framerate of our data (**300Hz**) and create a time vector that starts from the pre-stimulus period and continues in steps of 1/Hz, with a total length equal to Pre_stim + Post_stim.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Settings to cut events\nFs = 300 # framerate\nStep = 1000/Fs\n\nPre_stim = 100 # pre stimulus time (100ms)\nPost_stim = 2000 # post stimulus time (2000ms)\nPre_stim_samples = Pre_stim/Step  # pre stimulus in samples\nPost_stim_samples = Post_stim/Step  # post stimulus in samples\n\n# Time vector based on the event duration\nTime = seq(from = -Pre_stim, by=Step, length.out = (Pre_stim+Post_stim)/Step) # time vector\n```\n:::\n\n\n\n\nHere‚Äôs where the magic happens. We loop through each event listed in our **Events** dataframe. Each row in Events corresponds to a specific event (like a \"Circle\" or \"Square\" cue) that occurred for a specific subject during a specific trial.\n\nFor each event, we extract 2 key details:\n\n-   **Event** (to know if it's a Circle or Square cue)\n\n-   **TrialN** (to know which trial this event is part of)\n\nNext, we identify the rows of interest in our main dataframe. First, we locate the row where the time is closest to the onset of the event. Then, we select a range of rows that fall within the **Pre_stim** and **Post_stim** window around the event.\n\nFinally, we use these identified rows to add the event information. The Time, Event, and TrialN values are repeated across all the rows in this window, ensuring every row in the event window is properly labeled.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loop for each event \nfor (trial in 1:nrow(Events)){\n\n    # Extract the information\n    Event = Events[trial,]$Event\n    TrialN = Events[trial,]$TrialN\n    \n    # Event onset information\n    Onset = Events[trial,]$time\n    Onset_index = which.min(abs(Raw_data$time - Onset))\n    \n    # Find the rows to update based on pre post samples\n    rows_to_update = seq(Onset_index - Pre_stim_samples,\n                         Onset_index + Post_stim_samples-1)\n    \n    # Repeat the values of interest for all the rows\n    Raw_data[rows_to_update, 'time'] = Time\n    Raw_data[rows_to_update, 'Event'] = Event\n    Raw_data[rows_to_update, 'TrialN'] = TrialN\n}\n```\n:::\n\n\n\n\nPerfect! We‚Äôve successfully extended the event information backward and forward based on our Pre_stim and Post_stim windows. Now, it‚Äôs time to clean things up.\n\nSince we only care about the rows that are part of our trial of interest ‚Äîand because the event information is now repeated for each row during its duration‚Äî we‚Äôll remove all the rows that don‚Äôt belong to these event windows. This will leave us with a clean, focused dataset that only contains the data relevant to our analysis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTrial_data = Raw_data %>% \n    filter(Event %in% Events_to_keep)\n```\n:::\n\n\n\n\n### For all subjects\n\nGreat job making it this far! Fixing the data to make it usable in **PupillometryR** is definitely one of the trickiest parts. But... we‚Äôve only done this for **one subject** so far‚Äîoops! üòÖ No worries, though. Let‚Äôs automate this process by putting everything into a **loop** for each subject. In this loop, we‚Äôll fix the event structure for each subject, store each subject‚Äôs processed dataframe in a list, and finally combine all these dataframes into one single dataframe for further analysis. Let‚Äôs make it happen!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries and files --------------------------------------------------------------------\n\nlibrary(PupillometryR)  # Library to process pupil signal\nlibrary(tidyverse)  # Library to wrangle dataframes\nlibrary(patchwork)\n\ncsv_files = list.files(\n  path       = \"..\\\\..\\\\resources\\\\Pupillometry\\\\RAW\",\n  pattern    = \"\\\\.csv$\",   # regex pattern to match .csv files\n  full.names = TRUE         # returns the full file paths\n)\n\n\n# Event settings --------------------------------------------------------------------\n\nFs = 300 # framerate\nStep = 1000/Fs\n\nPre_stim = 100 # pre stimulus time (100ms)\nPost_stim = 2000 # post stimulus time (2000ms)\nPre_stim_samples = Pre_stim/Step  # pre stimulus in samples\nPost_stim_samples = Post_stim/Step  # post stimulus in samples\n\n# Time vector based on the event duration\nTime = seq(from = -Pre_stim, by=Step, length.out = (Pre_stim+Post_stim)/Step) # time vector\n\n\n# Event fixes --------------------------------------------------------------------\n\nList_of_subject_dataframes = list() # Empty list to be filled with dataframes\n\n# Loop for each subject\nfor (sub in 1:length(csv_files)) {\n  \n  Raw_data = read.csv(csv_files[sub]) # Raw data\n  Events = filter(Raw_data, Event %in% Events_to_keep) # Events\n  \n  \n  # Loop for each event \n  for (trial in 1:nrow(Events)){\n  \n      # Extract the information\n      Event = Events[trial,]$Event\n      TrialN = Events[trial,]$TrialN\n      \n      # Event onset information\n      Onset = Events[trial,]$time\n      Onset_index = which.min(abs(Raw_data$time - Onset))\n      \n      # Find the rows to update based on pre post samples\n      rows_to_update = seq(Onset_index - Pre_stim_samples,\n                           Onset_index + Post_stim_samples-1)\n      \n      # Repeat the values of interest for all the rows\n      Raw_data[rows_to_update, 'time'] = Time\n      Raw_data[rows_to_update, 'Event'] = Event\n      Raw_data[rows_to_update, 'TrialN'] = TrialN\n  }\n  \n  \n  # Filter only events of interest\n  Trial_data = Raw_data %>% \n    filter(Event %in% Events_to_keep)\n  \n  # Add daframe to list\n  List_of_subject_dataframes[[sub]] = Trial_data\n}\n\n# Combine the list of dataframes into 1 dataframe\nTrial_data = bind_rows(List_of_subject_dataframes)\n```\n:::\n\n\n\n\nNow we have our dataset all fixed and organized for each subject. Let‚Äôs take a look!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(Trial_data, aes(x = time, y = R_P, group = TrialN)) +\n  geom_line(aes(y = R_P, color = 'Pupil Right'), lwd = 1.2) +\n  geom_line(aes(y = L_P, color = 'Pupil Left'), lwd = 1.2) +\n  geom_vline(aes(xintercept = 0), linetype = 'dashed', color = 'black', lwd = 1.2) +\n  facet_wrap(~Subject) +\n  \n  ylim(1, 6) +\n  scale_color_manual(values = c('Pupil Right' = '#4A6274', 'Pupil Left' = '#E2725A')) +\n  \n  theme_bw(base_size = 35) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/PlotEvents-1.png){width=12000}\n:::\n:::\n\n\n\n\nAs you can see, the data structure is now completely transformed. We‚Äôve segmented the data into distinct time windows, with each segment starting at **-0.1 seconds (-100 ms)** and extending to **2 seconds (2000 ms)**. This new structure ensures consistency across all segments, making the data ready for further analysis.\n\n### Make PupillometryR data\n\nOk, now it‚Äôs time to start working with **PupillometryR**! üéâ\n\nIn the previous steps, we changed our event structure, and you might be wondering ‚Äî why all that effort? Well, it‚Äôs because PupillometryR needs the data in this specific format to do its magic. To get started, we‚Äôll pass our dataframe to the `make_pupillometryr_data()` function. If you‚Äôre already thinking, ‚ÄúOh no, not another weird object type that‚Äôs hard to work with!‚Äù ‚Äî don't worry! The good news is that the main object it creates is just a regular dataframe. That means we can still interact with like we‚Äôre used to. This makes the pre-processing steps much less frustrating. Let‚Äôs get started!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPupilR_data = make_pupillometryr_data(data = Trial_data,\n                                 subject = Subject,\n                                 trial = TrialN,\n                                 time = time,\n                                 condition = Event)\n```\n:::\n\n\n\n\nHere, we‚Äôre simply using the **`make_pupillometryr_data()`** function to pass in our data and specify which columns contain the key information. This tells PupillometryR where to find the crucial details, like subject IDs, events, and pupil measurements, so it knows how to structure and process the data properly.\n\n::: callout-tip\nIf you have extra columns that you want to keep in your **PupillometryR** data during preprocessing, you can pass them as a list using the **`other = c(OtherColumn1, OtherColumn2)`** argument. This allows you to keep these additional columns alongside your main data throughout most of the preprocessing steps.\n\nBut here‚Äôs a heads-up ‚Äî not all functions can keep these extra columns every time. For example, downsampling may not retain them since it reduces the number of rows, and it‚Äôs not always clear how to summarize extra columns. So, keep that in mind as you plan your analysis!\n:::\n\n#### Plot\n\nOne cool feature of the data created using **`make_pupillometryr_data()`** is that it comes with a simple, built-in `plot` function. This makes it super easy to visualize your data without needing to write tons of code. The plot function works by averaging the data over the `group` variable. So we can group over subject or condition. Here we use the `group` variable to focus on the **condition** and average over the subjects.\n\nIn this example, we‚Äôre plotting the L_P (left pupil) data, grouped by condition. The `plot()` function is actually just a ggplot2 wrapper, which means you can customize to a certain extent like any other ggplot. That‚Äôs why we can add elements to it, like **`theme_bw()`**, which gives the plot a cleaner, black-and-white look. Give it a go without adding anything and then learn to customize it!!\n\n::: callout-tip\n**Pro tip!** If you want more control over your plots, you can always use ggplot2. Remember, the Pupil data is just a regular dataframe, so you can plot it in any way you like!\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(PupilR_data, pupil = L_P, group = 'condition', geom = 'line') +\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/Pupilplot-1.png){width=3840}\n:::\n:::\n\n\n\n\n::: callout-note\nIn this tutorial, we‚Äôll use two methods to plot our data. We‚Äôll use the PupillometryR plot to visualize the average pupil response by condition, and we‚Äôll also use ggplot to manually plot our data. Both approaches are valid and offer unique benefits.\n\nThe PupillometryR plot provides a quick overview by automatically averaging pupil responses across condition levels, making it ideal for high-level trend visualization. On the other hand, ggplot gives you full control to visualize specific details or customize every aspect of the plot, allowing for deeper insights and flexibility.\n:::\n\n## Pre-processing\n\nNow that we have our pupillometry data in the required format we can actually start the pre-processing!!\n\n### Regress\n\nThe first step is to regress **L_P** against **R_P** (and vice versa) using a simple linear regression. This corrects small inconsistencies in pupil data caused by noise. The regression is done separately for each participant, trial, and time point, ensuring smoother and more consistent pupil dilation measurements.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRegressed_data = regress_data(data = PupilR_data,\n                                pupil1 = L_P,\n                                pupil2 = R_P)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `mutate()`:\n‚Ñπ In argument: `pupil1newkk = .predict_right(L_P, R_P)`.\n‚Ñπ In group 1: `Subject = \"Subject_1\"`, `TrialN = 1`, `Event = \"Circle\"`.\nCaused by error in `lm.fit()`:\n! 0 (non-NA) cases\n```\n\n\n:::\n:::\n\n\n\n\n**Pwa pwa pwaaaaa...!!**ü§¶‚Äç‚ôÇÔ∏è We got an error!\n\nWhat‚Äôs it saying? It‚Äôs telling us that one of the trials is completely full of **NAs**, and since there‚Äôs no data to work with, the function fails. This happens **a lot** when testing infants ‚Äî they don‚Äôt always do what we expect, like watching the screen. Instead, they move around or look away.\n\nWe‚Äôll deal with missing data properly later, but for now, we need a quick fix. What can we do? We can simply drop any trials where both pupils (L_P and R_P) are entirely NA. This way, we avoid errors and keep the analysis moving.\n\nSo let's filter our data and then redo the last two steps (make PupilR_data and then regress data)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter the trial data\nTrial_data = Trial_data %>%\n    group_by(Subject, TrialN) %>%  # group by Subject and TrialN\n    filter(!all(is.na(L_P) & is.na(R_P))) %>% # filter out if both R_P and L_P are all NA\n    ungroup()  # Remove grouping\n\n# Make pupilloemtryR data\nPupilR_data = make_pupillometryr_data(data = Trial_data,\n                                 subject = Subject,\n                                 trial = TrialN,\n                                 time = time,\n                                 condition = Event)\n# Regress data\nRegressed_data = regress_data(data = PupilR_data,\n                               pupil1 = L_P,\n                                pupil2 = R_P)\n```\n:::\n\n\n\n\nAnd now everything worked!! Perfect!\n\n### Mean pupil\n\nAs the next steps we will average the two pupil signals. This will create a new variable called mean_pupil\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMean_data = calculate_mean_pupil_size(data = Regressed_data, \n                                       pupil1 = L_P, \n                                       pupil2 = R_P)\n\nplot(Mean_data, pupil = mean_pupil, group = 'condition', geom = 'line')+\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/MeanData-1.png){width=3840}\n:::\n:::\n\n\n\n\n### Lowpass\n\nNow that we have a single pupil signal, we can move on to filtering it. The goal here is to remove fast noise and fluctuations that aren't relevant to our analysis. Why? Because we know that pupil dilation is a slow physiological signal, and those rapid changes are likely just noise from blinks, eye movements, or measurement errors. By filtering out these fast fluctuations, we can focus on the meaningful changes in pupil dilation that matter for our analysis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiltered_data = filter_data(data = Mean_data,\n                             pupil = mean_pupil,\n                             filter = 'median',\n                             degree = 11)\nplot(filtered_data, pupil = mean_pupil, group = 'condition', geom = 'line')+\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/Lowpass-1.png){width=3840}\n:::\n:::\n\n\n\n\nThere are different ways to filter the data in PupillometryR we suggest you check the actual package website and make decision based on your data ([`filter_data`](http://samforbes.me/PupillometryR/reference/filter_data.html)). Here we use a median filter based on a 11 sample window.\n\n### Downsample\n\nAs mentioned above, Pupil dilation is a slow signal, so 20Hz is enough ‚Äî no need for 300Hz. Downsampling reduces file size, speeds up processing, and naturally smooths the signal by filtering out high-frequency noise, all while preserving the key information we need for analysis. To downsample to 20Hz, we‚Äôll set the timebin size to 50 ms (since 1/20 = 0.05 seconds = 50 ms) and calculate the median for each time bin.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNewHz = 20\ntimebinSize = 1/NewHz\n\nDownsampled_data = downsample_time_data(data = filtered_data,\n                              pupil = mean_pupil,\n                              timebin_size = timebinSize,\n                              option = 'median')\nplot(Downsampled_data, pupil = mean_pupil, group = 'condition', geom = 'line') +\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/Downsample-1.png){width=3840}\n:::\n:::\n\n\n\n\n### Trial Rejection\n\nNow that our data is smaller and smoother, it‚Äôs a good time to take a look at it. It doesn‚Äôt make sense to keep trials that are mostly missing values, nor does it make sense to keep participants with very few good trials.\n\nWhile you might already have info on trial counts and participant performance from other sources (like video coding), PupillometryR has a super handy function to check this directly. This way, you can quickly see how many valid trials each participant has and decide which ones to keep or drop.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMissing_data = calculate_missing_data(Downsampled_data,\n                                       mean_pupil)\nhead(Missing_data, n=20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 √ó 3\n   Subject   TrialN Missing\n   <chr>      <int>   <dbl>\n 1 Subject_1      2  0.0603\n 2 Subject_1      3  0.125 \n 3 Subject_1      4  0.0746\n 4 Subject_1      5  0.106 \n 5 Subject_1      6  0.0746\n 6 Subject_1      7  0.0635\n 7 Subject_1      8  0.0587\n 8 Subject_1      9  0.0619\n 9 Subject_1     10  0.130 \n10 Subject_2      1  0.143 \n11 Subject_2      2  0.121 \n12 Subject_2      3  0.0619\n13 Subject_2      4  0     \n14 Subject_2      5  0.132 \n15 Subject_2      6  0.137 \n16 Subject_2      7  0.0841\n17 Subject_2      8  0.0968\n18 Subject_2      9  0.0841\n19 Subject_2     10  0.0508\n20 Subject_3      1  0.0587\n```\n\n\n:::\n:::\n\n\n\n\nThis gives us a new dataframe that shows the amount of missing data for each subject and each trial. While we could manually decide which trials and subjects to keep or remove, PupillometryR makes it easier with the **`clean_missing_data()`** function.\n\nThis function lets you set two % thresholds ‚Äî one for trials and one for subjects. Here, we‚Äôll set it to reject trials with more than 25% missing data (keep at least 75% of the data) and reject subjects with more than 25% missing data. This way, we ensure our analysis is based on clean, high-quality data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nClean_data = clean_missing_data(Downsampled_data,\n                                 pupil = mean_pupil,\n                                 trial_threshold = .75,\n                                 subject_trial_threshold = .75)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRemoving trials with a proportion missing > 0.75 \n ...removed 3 trials \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRemoving subjects with a proportion of missing trials > 0.75 \n ...removed 0 subjects \n```\n\n\n:::\n:::\n\n\n\n\nSee?! PupillometryR shows us exactly how many trials and subjects are being excluded from our dataframe based on our thresholds. Cool!\n\n::: callout-warning\nNote that this function calculates the percentage of missing trials based only on the trials present in the dataframe. For example, if a participant only completed one trial (and watched it perfectly) before the session had to stop, the percentage would be calculated on that single trial, and the participant wouldn‚Äôt be rejected.\n\nIf you have more complex conditions for excluding participants (e.g., based on total expected trials or additional criteria), you‚Äôll need to handle this manually to ensure subjects are dropped appropriately.\n:::\n\n### Fill the signal\n\nNow our data is clean, but‚Ä¶ while the average signal for each condition looks smooth (as seen in our plots), the data for each individual participant is still noisy. We can still spot blinks and missing data in the signal.\n\nTo handle this, we‚Äôll use interpolation to fill in the missing points. Interpolation \"connects the dots\" between gaps, creating a more continuous and cleaner signal. This step is crucial because large chunks of missing data can distort our analysis, and interpolation allows us to retain more usable data from each participant.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(Clean_data, aes(x = time, y = mean_pupil, group = TrialN, color= Event))+\n  geom_line( lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n\n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  labs(y = 'Pupil Size')+\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/PlotBlink-1.png){width=3840}\n:::\n:::\n\n\n\n\nSo to remove these missing values we can interpolate our data. Interpolating is easy with PupillometryR we can simply:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nInt_data = interpolate_data(data = Clean_data,\n                             pupil = mean_pupil,\n                             type = 'linear')\n\nggplot(Int_data, aes(x = time, y = mean_pupil, group = TrialN, color = Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n\n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  labs(y = 'Pupil Size')+\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/WrongInterpolation-1.png){width=3840}\n:::\n:::\n\n\n\n\n**Done!!** Well, you‚Äôve probably noticed something strange... When there‚Äôs a blink, the pupil signal can rapidly decrease until it‚Äôs completely missing. Right now, this drop gets interpolated, and the result is a weird, unrealistic curve where the signal dips sharply and then smoothly recovers. This makes our data look horrible! üò©\n\n**Let‚Äôs fix it!**\n\nTo do this, we‚Äôll use PupillometryR‚Äôs blink detection functions. There are two main ways to detect blinks:\n\n1.  [**Based on size**](http://samforbes.me/PupillometryR/reference/detect_blinks_by_size.html) ‚Äî detects pupil size.\n\n2.  [**Based on velocity**](http://samforbes.me/PupillometryR/reference/detect_blinks_by_velocity.html) ‚Äî detects rapid changes in pupil size (which happens during blinks).\n\nHere, we‚Äôll use detection by velocity. We set a velocity threshold to detect when the pupil size changes too quickly. To ensure we capture the full blink, we use `extend_forward` and `extend_back` to expand the blink window, including the fast decrease in pupil size. The key idea is to make the entire blink period NA, not just the moment the pupil disappears. This prevents interpolation from creating unrealistic artifacts. When we interpolate, the process skips over the entire blink period, resulting in a cleaner, more natural signal.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBlink_data = detect_blinks_by_velocity(\n    Clean_data,\n    mean_pupil,\n    threshold = 0.1,\n    extend_forward = 70,\n    extend_back = 70)\n\nggplot(Blink_data, aes(x = time, y = mean_pupil, group = TrialN, color=Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n\n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  labs(y = 'Pupil Size')+\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/BlinkRemoval-1.png){width=3840}\n:::\n:::\n\n\n\n\nSee !! now the rapid shrinking disappeared and we can now interpolate\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nInt_data = interpolate_data(data = Blink_data,\n                             pupil = mean_pupil,\n                             type = 'linear')\n\nggplot(Int_data, aes(x = time, y = mean_pupil, group = TrialN, color=Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n\n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  labs(y = 'Pupil Size')+\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/Interpolation2-1.png){width=3840}\n:::\n:::\n\n\n\n\nLook how beautiful our signal is now!! üòç Good job!!!\n\n::: callout-caution\nYou won‚Äôt always run into blink issues like this. Downsampling and filtering usually handle rapid changes during earlier preprocessing steps. Whether this happens can depend on the tracker, sampling rate, or even the population you‚Äôre testing. **In this simulated data, we exaggerated the blink effects on purpose to show you how to spot and fix them!** Thus, blink detection may not always be necessary. The best approach is to check your data before deciding. And how do you check it? **Plotting**! Plotting your signal is the best way to see if blinks are causing rapid drops or if you‚Äôre just dealing with missing data. Let the data guide your decisions.\n:::\n\n### Baseline Correction\n\nGood job getting this far!! We‚Äôre now at the final step of our pre-processing: baseline correction.\n\nBaseline correction helps remove variability between trials and participants, like differences in baseline pupil size caused by individual differences, fatigue, or random fluctuations. By doing this, we can focus only on the variability caused by our paradigm. This step ensures that any changes we see in pupil size are truly driven by the experimental conditions, not irrelevant noise. To further adjust the data, we‚Äôll subtract the calculated baseline, ensuring the values start at **0** instead of **-100**. Finally, to make the next steps of analysis easier, we‚Äôll select only the columns of interest, dropping any irrelevant ones.\n\nLet‚Äôs get it done!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nBase_data = baseline_data(data = Int_data,\n                           pupil = mean_pupil,\n                           start = -100,\n                           stop = 0)\n\n# Remove the baseline\nFinal_data = subset_data(Base_data, start = 0) %>% \n  select(Subject, Event, TrialN, mean_pupil, time)\n```\n:::\n\n\n\n\nLet's plot it to see what baseline correction and removal are actually doing!! We will plot both the average signal using the `plot` function (with some addition information about color and theme) and using ggplot to plot the data for each subject separately.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nOne = plot(Final_data, pupil = mean_pupil, group = 'condition')+\n  theme_bw(base_size = 45) +\n  theme(legend.position = 'none')\n\n\nTwo = ggplot(Final_data, aes(x = time, y = mean_pupil, group = TrialN, color = Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n\n  facet_wrap(~Subject)+\n\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  labs(y = 'Pupil Size')+\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n# Using patchwork to put the plot together\nOne / Two\n```\n\n::: {.cell-output-display}\n![](PupilPreprocessing_files/figure-html/FinalPlot-1.png){width=3840}\n:::\n:::\n\n\n\n\n### Save and analysis\n\nThis tutorial will not cover the analysis of pupil dilation. We‚Äôll stop here since, after baseline correction, the data is ready to be explored and analyzed. From this point on, we‚Äôll shift from **pre-processing** to **analysis**, so it‚Äôs a good idea to save the data as a simple *.csv* file for easy access and future use.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(Final_data, \"..\\\\..\\\\resources\\\\Pupillometry\\\\Processed\\\\Processed_PupilData.csv\")\n```\n:::\n\n\n\n\nThere are multiple ways to analyze pupil data, and we‚Äôll show you some of our favorite methods in a dedicated tutorial: **Analyze Pupil Dilation**.\n\n## Cite PupillometryR\n\nIf you decide to use PupillometryR in your analysis, don‚Äôt forget to cite it! Proper citation acknowledges the authors' work and supports the development of such valuable tools.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncitation(\"PupillometryR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTo cite PupillometryR in publications use:\n\n  Forbes, S. H. (2020). PupillometryR: An R package for preparing and\n  analysing pupillometry data. Journal of Open Source Software, 5(50),\n  2285. https://doi.org/10.21105/joss.02285\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {PupillometryR: An R package for preparing and analysing pupillometry data},\n    author = {Samuel H. Forbes},\n    journal = {Journal of Open Source Software},\n    year = {2020},\n    volume = {5},\n    number = {50},\n    pages = {2285},\n    doi = {10.21105/joss.02285},\n  }\n```\n\n\n:::\n:::\n\n\n\n\n## All code\n\nHere below we report the whole code we went trough this tutorial as an unique script to make it easier for you to copy and explore it in it's entirety.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries and files --------------------------------------------------------------------\n\nlibrary(PupillometryR)  # Library to process pupil signal\nlibrary(tidyverse)  # Library to wrangle dataframes\nlibrary(patchwork)\n\ncsv_files = list.files(\n  path       = \"..\\\\..\\\\resources\\\\Pupillometry\\\\RAW\",\n  pattern    = \"\\\\.csv$\",   # regex pattern to match .csv files\n  full.names = TRUE         # returns the full file paths\n)\n\n\n# Prepare data --------------------------------------------------------------------\n\n## Event settings --------------------------------------------------------------------\n\n# Settings to cut events\nFs = 300 # framerate\nStep = 1000/Fs\n\nPre_stim = 100 # pre stimulus time (100ms)\nPost_stim = 2000 # post stimulus time (2000ms)\nPre_stim_samples = Pre_stim/Step  # pre stimulus in samples\nPost_stim_samples = Post_stim/Step  # post stimulus in samples\n\n# Time vector based on the event duration\nTime = seq(from = -Pre_stim, by=Step, length.out = (Pre_stim+Post_stim)/Step) # time vector\n\n\n## Event fixes --------------------------------------------------------------------\n\nList_of_subject_dataframes = list() # Empty list to be filled with dataframes\n\n# Loop for each subject\nfor (sub in 1:length(csv_files)) {\n  \n  Raw_data = read.csv(csv_files[sub]) # Raw data\n  Events = filter(Raw_data, Event %in% Events_to_keep) # Events\n\n  \n  # Loop for each event \n  for (trial in 1:nrow(Events)){\n  \n      # Extract the information\n      Event = Events[trial,]$Event\n      TrialN = Events[trial,]$TrialN\n      \n      # Event onset information\n      Onset = Events[trial,]$time\n      Onset_index = which.min(abs(Raw_data$time - Onset))\n      \n      # Find the rows to update based on pre post samples\n      rows_to_update = seq(Onset_index - Pre_stim_samples,\n                           Onset_index + Post_stim_samples-1)\n      \n      # Repeat the values of interest for all the rows\n      Raw_data[rows_to_update, 'time'] = Time\n      Raw_data[rows_to_update, 'Event'] = Event\n      Raw_data[rows_to_update, 'TrialN'] = TrialN\n  }\n  \n  \n  # Filter only events of interest\n  Trial_data = Raw_data %>% \n    filter(Event %in% Events_to_keep)\n  \n  # Add daframe to list\n  List_of_subject_dataframes[[sub]] = Trial_data\n}\n\n# Combine the list of dataframes into 1 dataframe\nTrial_data = bind_rows(List_of_subject_dataframes)\n\n\n### Plot Raw Data -----------------------------------------------------------------\n\nggplot(Raw_data, aes(x = time, y = R_P)) +\n  geom_line(aes(y = R_P, color = 'Pupil Right'), lwd = 1.2) +\n  geom_line(aes(y = L_P, color = 'Pupil Left'), lwd = 1.2) +\n  geom_vline(data = Raw_data |> dplyr::filter(!is.na(Event)), aes(xintercept = time, linetype = Event), lwd = 1.3) +\n  \n  theme_bw(base_size = 45) +\n  ylim(1, 6) +\n  labs(color= 'Signal', y='Pupil size')+\n  scale_color_manual(\n    values = c('Pupil Right' = '#4A6274', 'Pupil Left' = '#E2725A') )  +\n  theme(\n    legend.position = 'bottom'  ) +\n  guides(\n    color = guide_legend(override.aes = list(lwd = 20)),\n    linetype = guide_legend(override.aes = list(lwd = 1.2))\n  )\n\n\n\n# Pre-processing -----------------------------------------------------------------\n\n## Filter Out Trials with all NA -----------------------------------------------------------------\n\nTrial_data = Trial_data %>%\n  group_by(Subject, TrialN) %>%\n  filter(!all(is.na(L_P) & is.na(R_P))) %>%\n  ungroup()\n\n\n## Make PupillometryR Data -----------------------------------------------------------------\nPupilR_data = make_pupillometryr_data(data = Trial_data,\n                                      subject = Subject,\n                                      trial = TrialN,\n                                      time = time,\n                                      condition = Event)\n\n### Plot ------------------------------------------------------------------\nplot(PupilR_data, pupil = L_P, group = 'condition', geom = 'line') +\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n\n## Regress Data -----------------------------------------------------------------\n\nRegressed_data = regress_data(data = PupilR_data,\n                               pupil1 = L_P,\n                               pupil2 = R_P)\n\n\n## Calculate Mean Pupil -----------------------------------------------------------------\n\nMean_data = calculate_mean_pupil_size(data = Regressed_data, \n                                       pupil1 = L_P, \n                                       pupil2 = R_P)\n\n### Plot --------------------------------------------------------------------\n\nplot(Mean_data, pupil = mean_pupil, group = 'condition', geom = 'line')+\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n\n## Lowpass Filter -----------------------------------------------------------------\n\nfiltered_data = filter_data(data = Mean_data,\n                             pupil = mean_pupil,\n                             filter = 'median',\n                             degree = 11)\n\n### Plot --------------------------------------------------------------------\n\nplot(filtered_data, pupil = mean_pupil, group = 'condition', geom = 'line')+\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n\n## Downsample -----------------------------------------------------------------\n\nNewHz = 20\n\ntimebinSize = 1 / NewHz\n\nDownsampled_data = downsample_time_data(data = filtered_data,\n                                         pupil = mean_pupil,\n                                         timebin_size = timebinSize,\n                                         option = 'median')\n\n# Plot --------------------------------------------------------------------\n\nplot(Downsampled_data, pupil = mean_pupil, group = 'condition', geom = 'line') +\n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n\n## Calculate Missing Data -----------------------------------------------------------------\n\nMissing_data = calculate_missing_data(Downsampled_data, mean_pupil)\n\n\n## Clean Missing Data -----------------------------------------------------------------\n\nClean_data = clean_missing_data(Downsampled_data,\n                                 pupil = mean_pupil,\n                                 trial_threshold = .75,\n                                 subject_trial_threshold = .75)\n\n### Plot --------------------------------------------------------------------\n\nggplot(Clean_data, aes(x = Time, y = mean_pupil, group = TrialN, color= Event))+\n  geom_line( lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n  \n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n\n## Detect Blinks -----------------------------------------------------------------\n\nBlink_data = detect_blinks_by_velocity(\n  Clean_data,\n  mean_pupil,\n  threshold = 0.1,\n  extend_forward = 50,\n  extend_back = 50)\n\n### Plot --------------------------------------------------------------------\n\nggplot(Blink_data, aes(x = time, y = mean_pupil, group = TrialN, color=Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n  \n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\n\n## Interpolate Data -----------------------------------------------------------------\n\nInt_data = interpolate_data(data = Clean_data,\n                             pupil = mean_pupil,\n                             type = 'linear')\n\n### Plot --------------------------------------------------------------------\n\nggplot(Int_data, aes(x = Time, y = mean_pupil, group = TrialN, color = Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n\n  facet_wrap(~Subject)+\n  ylim(1,6)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20)))\n\n\n# Baseline correction -----------------------------------------------------\n\nBase_data = baseline_data(data = Int_data,\n                           pupil = mean_pupil,\n                           start = -100,\n                           stop = 0)\n\n# Remove the baseline\nFinal_data = subset_data(Base_data, start = 0)\n\n\n### Final plot --------------------------------------------------------------\n\nOne = plot(Final_data, pupil = mean_pupil, group = 'condition')+\n  theme_bw(base_size = 45) +\n  theme(legend.position = 'none')\n\n\nTwo = ggplot(Final_data, aes(x = time, y = mean_pupil, group = TrialN, color = Event))+\n  geom_line(lwd =1.2)+\n  geom_vline(aes(xintercept = 0), linetype= 'dashed', color = 'black', lwd =1.2)+\n  \n  facet_wrap(~Subject)+\n  \n  theme_bw(base_size = 45) +\n  theme(\n    legend.position = 'bottom', \n    legend.title = element_blank()) +\n  guides(color = guide_legend(override.aes = list(lwd = 20))) \n\nOne / Two\n\n\n\n# Save data ---------------------------------------------------------------\n\nwrite.csv(Final_data, \"..\\\\..\\\\resources\\\\Pupillometry\\\\Processed\\\\Peocessed_PupilData.csv\")\n```\n:::",
    "supporting": [
      "PupilPreprocessing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}