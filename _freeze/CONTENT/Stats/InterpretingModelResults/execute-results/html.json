{
  "hash": "d2e70ca3689ad4667c1bdf00ed9f3578",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Interpreting Model Results\"\n\nauthor: \"Tommaso Ghilardi\"\nauthor-meta: \"Tommaso Ghilardi\"\n\nexecute:\n  eval: true\n\ndescription-meta: \"Learn what a the summary of a linear model means!\"\nkeywords-meta: \"R, lm, Linear models, statistics, analysis, psychology, tutorial, experiment, DevStart, developmental science\"\n\ndrafts: True\ndraft-mode: unlinked\n---\n\n\n\nIn the previous tutorial we run our first model and we checked whether the model met the assumptions. You have to agree it was easy and fun! Now the real challenge begins.\n\nWe want to understand what the model we run is telling us.\n\nFirst thing first let's re-run the model and check its ouptut\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = read.csv(\"..\\\\..\\\\resources\\\\Stats\\\\Dataset.csv\")\nmod_lm = lm(LookingTime ~ Event_trial*Event, data = df)\nsummary(mod_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = LookingTime ~ Event_trial * Event, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-772.0 -159.7   -6.1  190.5  607.1 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             1390.1655    29.1769  47.646   <2e-16 ***\nEvent_trial               -7.5998     2.9897  -2.542   0.0113 *  \nEventReward               99.8279    39.3360   2.538   0.0114 *  \nEvent_trial:EventReward    0.1332     3.7240   0.036   0.9715    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 253.2 on 656 degrees of freedom\n  (140 observations deleted due to missingness)\nMultiple R-squared:  0.05147,\tAdjusted R-squared:  0.04713 \nF-statistic: 11.87 on 3 and 656 DF,  p-value: 1.417e-07\n```\n\n\n:::\n:::\n\n\n\n# Interpreting the results\n\nHere the results again. As we mentioned in the previous tutorial the pvalue is what everyone goes crazy about...but its just 1 of the information that the model is giving us. let's dive in piece by piece.\n\n-   **Call**:\n\n    This section just report the function call that we passed to `lm()`.\n\n-   **Residuals**:\n\n    This section reports the residuals of the model. Residuals represent the difference between the observed values and the values predicted by the model. Essentially, how much variability remains after fitting our variable to the model.\n\n-   **Coefficients**:\n\n    This section displays the estimated coefficients of the regression model,the stand error of the estimation, the t-value and finally the p-value!\n\n-   **Model Fit:**\n\n    The last section reports different statistics about the model fit:\n\n    -   **Residual standard error:** Average distance between observed values and the regression line. Smaller is better.\n\n    -   **Multiple R-Squared:** Proportion of response variable variance explained by predictors. Ranges from 0 to 1; closer to 1 is better.\n\n    -   **Adjusted R-squared:** R-squared modified for the number of predictors. Useful for comparing models with different numbers of predictors.\n\n    -   **T-value and p-value:** Indicate if the model provides a better fit than a model with no predictors. A p-value \\< 0.05 suggests the model is useful.\n\n## Coeffiecients\n\nThe Coefficient section if indubitably the most important section of the summary of our model. However what are all these numbers? Let's go together through the most challenging information:\n\n### (Intercept)\n\nThe intercept often confuses who approaches for the first time linear models. What is it? The (Intercept) represent the reference levels where all our predictors (`Event_trial` and `Event`) are **0**. Now you may ask...how can `Event` be 0? It is a categorical variable, it can't be 0!!!! `Event_trial == 0`...sure ....but `Event`??\n\nYou are correct. When a model encounters a categorical variable it selects the first level of such variable as reference level. If you take another look to our model summary you can see that there are information both for the `hammer`and `Reward` level of the `Event`variable but nothing about the **NoReward** level. This is because the **NoReward** level has been selected by the model as the reference level and it is thus represented in the intercept value!\n\nwe can simply visualize it as:\\\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-2-1.png){width=3000}\n:::\n:::\n\n\n\nAs you can see, the intercept is pretty straightforward—it gives us the estimate when everything is set to 0, both for continuous and categorical variables. It’s like the starting point of your model, where all the predictors (in this case, **NoReward** was selected as the reference or 0 level for the categorical variable) are at their reference level or baseline value.\n\n### Tools\n\nAwesome! Now that we’ve got the intercept down, let’s take a look at the rest of the model output. We’ll skip over the `Event_trial` variable for now and focus on what’s happening with the tools.\n\nAt first, the results for `Event [hammer]` and `Event [Reward]` might look like they’re giving us the values for the hammer and Reward. Super easy, right?\n\nWell... not exactly!\n\n**In linear models, each coefficient shows the DIFFERENCE in relation to the intercept (the 0 or the reference level), not the exact value of the Event itself.**\n\nIt sounds a bit confusing, but let’s break it down. The coefficient for `Event [hammer]` is actually just the difference between the intercept (2.81) and the coefficient for `Event [hammer]` (3.60). So, hammer’s total value = 2.81 + 3.60 = 6.41! Same goes for the Reward, where the total is 2.81 + 2.79 = 5.60.\n\nSee? Not too bad! Let’s visualize it and make it even clearer!\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-3-1.png){width=3000}\n:::\n:::\n\n\n\n### Time\n\nSo, interpreting the coefficients for categorical variables wasn’t too tricky, right? But what about continuous variables like `Event_trial`?\n\nNo worries, it’s actually pretty straightforward! The coefficient for a continuous variable represents the slope, or the incline, of the line for that variable.\n\nIn simpler terms, it shows how much the outcome (in this case, `LookingTime`) changes for each unit increase in the continuous variable (`Event_trial`). So, in our case the coefficient for `Event_trial` is -7.5, this means that for each unit increase in `Event_trial`, the LookingTime is expected to increase by -7.5 units (assuming all other variables stay the same).\n\n::: callout-important\nIn this case the continuous effect represent how\n:::\n\nEven easier..let's plot again!\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-4-1.png){width=3000}\n:::\n:::\n\n\n\n### Interaction\n\nAlright, now we're getting to the final steps! Let's talk about the interaction between `Event_trial` and `Event`! Now, we're not just dealing with a single factor or continuous variable, but looking at how they interact with each other. Don't worry—if you understood the previous steps, this will be a breeze!\n\nWe'll take it step by step and look at the first interaction we see in our model parameters. Let’s start by checking out the interaction between `Event_trial` and `Event [Reward]`.\n\nThe interaction term between `Event_trial` and ``` Event [``Reward``] ``` tells us how the relationship between `Event_trial` and `LookingTime` changes when we switch from the reference Event (**NoReward**) to the **Reward**. To put it simply, the coefficient for this interaction will show you how much more (or less) the effect of `Event_trial` on `LookingTime` changes when using the hammer compared to the baseline (**NoReward**). If the coefficient is positive, it means that as `Event_trial` increases, `LookingTime` increases more when using the hammer than when using the **NoReward**. If it’s negative, it means the `LookingTime` increase is smaller with the hammer than with the **NoReward**.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-5-1.png){width=3000}\n:::\n:::\n",
    "supporting": [
      "InterpretingModelResults_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}