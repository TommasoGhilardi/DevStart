{
  "hash": "42af7392d32038d1b099f6b4c480f562",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Interpreting Model Results\"\n\nauthor: \"Tommaso Ghilardi\"\nauthor-meta: \"Tommaso Ghilardi\"\n\nexecute:\n  eval: true\n\ndescription-meta: \"Learn what a the summary of a linear model means!\"\nkeywords-meta: \"R, lm, Linear models, statistics, analysis, psychology, tutorial, experiment, DevStart, developmental science\"\n\ndrafts: True\ndraft-mode: unlinked\n---\n\n\n\nIn the previous tutorial we run our first model and we checked whether the model met the assumptions. You have to agree it was easy and fun! Now the real challenge begins.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'tidyr' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'readr' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'dplyr' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'stringr' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(easystats)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'easystats' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n# Attaching packages: easystats 0.7.3 (red = needs update)\n✖ bayestestR  0.14.0   ✖ correlation 0.8.5 \n✔ datawizard  0.13.0   ✔ effectsize  0.8.9 \n✔ insight     0.20.5   ✖ modelbased  0.8.8 \n✖ performance 0.12.3   ✖ parameters  0.22.2\n✔ report      0.5.9    ✔ see         0.9.0 \n\nRestart the R-Session and update packages with `easystats::easystats_update()`.\n```\n\n\n:::\n\n```{.r .cell-code}\ndf = read.csv(\"..\\\\..\\\\resources\\\\Stats\\\\LM_SimulatedData.csv\")\nmod = lm(performance ~ time*tool, data = df)\n```\n:::\n\n\n\n# Interpreting the results\n\nVery cool!! we have our result!!\n\nBut what is it saying?? As you can see the summary is divided in subsections. Lets go trough them piece by piece.\n\n-   **Call**:\n\n    This section just report the function call that we passed to `lm()`.\n\n-   **Residuals**:\n\n    This section reports the residuals of the model. Residuals represent the difference between the observed values and the values predicted by the model. Essentially, how much variability remains after fitting our variable to the model.\n\n-   **Coefficients**:\n\n    This section displays the estimated coefficients of the regression model,the stand error of the estimation, the t-value and finally the p-value!\n\n-   **Model Fit:**\n\n    The last section reports different statistics about the model fit:\n\n    -   **Residual standard error:** Average distance between observed values and the regression line. Smaller is better.\n\n    -   **Multiple R-Squared:** Proportion of response variable variance explained by predictors. Ranges from 0 to 1; closer to 1 is better.\n\n    -   **Adjusted R-squared:** R-squared modified for the number of predictors. Useful for comparing models with different numbers of predictors.\n\n    -   **F-statistic and p-value:** Indicate if the model provides a better fit than a model with no predictors. A p-value \\< 0.05 suggests the model is useful.\n\n## Coeffiecients\n\nThe Coefficient section if indubitably the most important section of the summary of our model. However what are all these numbers? Let's go together through the most challenging information:\n\n### (Intercept)\n\nThe intercept often confuses who approaches for the first time linear models. What is it? The (Intercept) represent the reference levels where all our predictors (`time` and `tool`) are 0. Now you may ask...how can `tool` be 0? It is a categorical variable, it can't be 0!!!!\n\nYou are correct. When a model encounters a categorical variable it selects the first level of such variable as reference level. If you take another look to our model summary you can see that there are information both for the `hammer`and `spoon` level of the `tool`variable but nothing about the `brush` level. This is because the `brush` level has been selected by the model as the reference level and it is thus represented in the intercept value!\n\nwe can simply visualize it as:\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nmodel_p = parameters(mod)\n\n# Define intercept and slope for the brush\nintercept_brush <- model_p[1,2]\nintercept_brush_se <- model_p[1,3]\n\n# To create estimates\ntime_values <- seq(0, 10, by = 0.5)\n\n\nggplot()+\n  \n  # Cartesian lines\n  geom_vline(xintercept = 0)+\n  geom_hline(yintercept = 0)+\n  \n  # Intercept\n  annotate(\"point\", x = 0, y = intercept_brush, size = pi * intercept_brush_se^2, alpha = 0.3, color = 'darkred') +\n  annotate(\"point\", x = 0, y = intercept_brush, color = 'darkred') +\n  annotate(\"text\", x = -0.5, y=intercept_brush*1.15, label='(Intercept)')+\n  \n  # Plot addition information\n  coord_cartesian(xlim = c(-1,5), ylim = c(-1,5))+\n  labs(y = 'Performance', x = 'Time')+\n  theme_bw(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-2-1.png){width=2400}\n:::\n:::\n\n\n\n## Tools\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define intercept and slope for the brush\nintercept_brush <- model_p[1,2]\nintercept_brush_se <- model_p[1,3]\n\nintercept_hammer <- model_p[3,2] + intercept_brush\nintercept_hammer_se <- model_p[3,3]\n\nintercept_spoon <- model_p[4,2]+ intercept_brush\nintercept_spoon_se <- model_p[4,3]\n\n\nggplot() +\n  \n  # Intercept (brush)\n  annotate(\"point\", x = 0, y = intercept_brush, size = pi * intercept_brush_se^2, alpha = 0.3, color = 'darkred') +\n  annotate(\"point\", x = 0, y = intercept_brush, color = 'darkred', size = 4) +\n  \n  # Hammer\n  annotate(\"point\", x = 1, y = intercept_hammer, size = pi * intercept_hammer_se^2, alpha = 0.3, color = 'darkblue') +\n  annotate(\"point\", x = 1, y = intercept_hammer, color = 'darkblue', size = 4) +\n  \n  # Spoon\n  annotate(\"point\", x = 2, y = intercept_spoon, size = pi * intercept_spoon_se^2, alpha = 0.3, color = 'darkgreen') +\n  annotate(\"point\", x = 2, y = intercept_spoon, color = 'darkgreen', size = 4) +\n  \n  # Set the limits for x and y axes\n  coord_cartesian(xlim = c(-0.1, 2.2), ylim = c(0, 7)) +\n  \n  # Customize x-axis breaks\n  scale_x_continuous(breaks = c(0, 1, 2), labels = c('brush','hammer','spoon')) +\n  \n  # Labels and theme\n  labs(y = 'Performance', x = 'Tools') +\n  theme_bw(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-3-1.png){width=2400}\n:::\n:::\n\n\n\n### Time\n\nThe estimates are the slopes (the inclination) of the lines of each predictor. However they should be interpreted as a difference from the intercept.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define intercept and slope for the brush\nintercept_brush <- model_p[1,2]\nintercept_brush_se <- model_p[1,3]\n\nslope_brush <- model_p[2,2]\nslope_brush_se <- model_p[2,3]\n\n# To create estimates\ntime_values <- seq(-1, 4, by = 0.25)\n\n# Create a data frame\ndf_brush <- data.frame(time = time_values,\n                       est_performance = intercept_brush + slope_brush * time_values)\n\n\n\n# Function to create an arc between two angles with a custom center\ngenerate_circle_piece <- function(center = c(0, 0), radius = 1, start_angle = 0, end_angle = 90) {\n  # Convert angles to radians\n  start_rad <- start_angle * pi / 180\n  end_rad <- end_angle * pi / 180\n  \n  # Generate points for the piece of the circle\n  theta <- seq(start_rad, end_rad, length.out = 100)\n  x <- center[1] + radius * cos(theta)\n  y <- center[2] + radius * sin(theta)\n  \n  # Create a data frame for the circle points\n  circle_data <- data.frame(x = x, y = y)\n  \n  return(circle_data)\n}\n# Create data for the arc with the angle calculated from the slope, using the new center\narc_data <- generate_circle_piece(center = c(0, intercept_brush), radius = 0.5, start_angle = 0, end_angle =  atan(slope_brush) * (180 / pi))\n\n\nggplot(df_brush, aes(x = time, y = est_performance))+\n  \n  # Cartesian lines\n  geom_vline(xintercept = 0)+\n  # geom_hline(yintercept = 0)+\n  # \n  # Time\n  geom_path(data = arc_data, aes(x = x, y = y), color = 'green', size = 1.5) +\n  geom_hline(yintercept = intercept_brush, linetype = 'dashed', color = 'darkgray')+\n  geom_line(color = \"darkred\", size = 1) +\n\n  # Intercept\n  annotate(\"point\", x = 0, y = intercept_brush, size = pi * intercept_brush_se^2, alpha = 0.3, color = 'darkred') +\n  annotate(\"point\", x = 0, y = intercept_brush, color = 'darkred', size = 4) +\n\n  # Text\n  annotate(\"text\", x = -0.5, y=2.825, label='(Intercept)')+\n  annotate(\"text\", x = 0.8, y=2.82, label='time')+\n\n  \n  \n  # Plot addition information\n  # coord_cartesian(xlim = c(-1,4), ylim = c(-1,5))+\n  labs(y = 'Performance', x = 'Time')+\n  theme_bw(base_size = 20)\n```\n\n::: {.cell-output-display}\n![](InterpretingModelResults_files/figure-html/unnamed-chunk-4-1.png){width=2400}\n:::\n:::\n",
    "supporting": [
      "InterpretingModelResults_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}