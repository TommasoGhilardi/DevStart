---
title: Create an eye-tracking experiment
execute:
  eval: false

pagetitle: Create an eye-tracking experiment
author-meta: Tommaso Ghilardi
description-meta: Learn how to record eyetracking data in your psychopy experiment using Tobii SDK, tobii_research
keywords: PsychoPy, Python, eye-tracking, tobii, tobii_research, experimental psychology, tutorial, experiment, DevStart, developmental science
---

This page will show you how to collect eye-tracking data in a simple psychopy paradigm. We will use the same paradigm that we built together in the [Getting started with Psychopy](GettingStartedWithPsychopy.qmd) tutorial. If you have not done that tutorial yet, please go through it first.

::: callout-caution
**Tobii eye-tracker**

Note that this tutorial is specific for using **Tobii eye-trackers**. The general steps and idea are obviously applicable to other eye-trackers, but the specific code and packages vary depending on the device.
:::

# Tobii_sdk

To start we will look into how to connect and talk to our Tobii eyetracker. We have different options to use our Tobii eye tracker. One option is to use the software that Tobii provides. However, this software is very expensive and sometimes not flexible enough for all the studies. We prefer to use the **SDK** that Tobii provides.

An **SDK** is a collection of tools and programs for developing applications for a specific platform or device. We will use the **Python Tobii SDK** that lets us easily find and get data from our Tobii eye tracker.

## Install

To install the Python Tobii SDK, we can simply run this command in our conda terminal:

``` bash
pip install tobii_research
```

Great! We have installed the Tobii SDK.

## Connect to the eye-tracker

So how does this library work, how do we connect to the eye-tracker and collect our data? Very good questions!

The `tobii_research` documentation is quite extensive and describes in detail a lot of functions and data classes that are very useful. However, we don't need much to start our experiment.

First we need to identify all the eye trackers connected to our computer. Yes, plural, `tobii_research` will return a list of all the eye trackers connected to our computer. 99.99999999% of the time you will only have 1 eye tracker connected, so we can just select the first (and usually only) eye tracker found.

```{python}
# Import tobii_research library
import tobii_research as tr

# Find all connected eye trackers
found_eyetrackers = tr.find_all_eyetrackers()

# We will just use the first one
Eyetracker = found_eyetrackers[0]
```

Perfect!! We have identified our eye-trackers, we have selected the first one (and only).

We are now ready to use our eye-tracker to collect some data...but how?

## Collect data

Tobii_research has a cool way of telling us what data we are collecting at each time point. It uses a callback function. What is a callback function, you ask? It is a function that tobii runs each time it has a new data point. Let's say we have an eye tracker that collects data at 300Hz (300 samples per second): the function will be called every time the tobii has one of those 300 samples.

This callback function will give us a `gaze_data` object. This object contains multiple information of that collected sample and we can simply select the information we care about. In our case we want:

-   the `system_time_stamp`, our time variable

-   the `left_eye.gaze_point.position_on_display_area`, it contains the coordinates on the screen of the left eye (both x and y)

-   the `right_eye.gaze_point.position_on_display_area`, it contains the coordinates on the screen of the right eye (both x and y)

-   the `left_eye.pupil.diameter`, is the pupil diameter of the left eye

-   the `right_eye.pupil.diameter`, is the pupil diameter of the right eye

-   the `left_eye.gaze_point.validity`, this is a value that tells us whether we think the recognition is ok or not

Here is our callback function:

```{python}
def gaze_data_callback(gaze_data):

    # Extract the data we are interested in
    t  = gaze_data.system_time_stamp
    lx = gaze_data.left_eye.gaze_point.position_on_display_area[0]
    ly = gaze_data.left_eye.gaze_point.position_on_display_area[1]
    lp = gaze_data.left_eye.pupil.diameter
    lv = gaze_data.left_eye.gaze_point.validity
    rx = gaze_data.right_eye.gaze_point.position_on_display_area[0]
    ry = gaze_data.right_eye.gaze_point.position_on_display_area[1]
    rp = gaze_data.right_eye.pupil.diameter
    rv = gaze_data.right_eye.gaze_point.validity
```

So, how we said this function will be called every time tobii has a new data-point. COOL!! Now we need to tell tobii to run this function we have created. This is very simple we can just:

```{python}
# Start the callback function
Eyetracker.subscribe_to(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
```

We are telling tobii that we are interested in the `EYETRACKER_GAZE_DATA` and that we want it to pass it to our function `gaze_data_callback`.

## Triggers/Events

So, as we have seen, our callback function can access the tobii data and tell us what it is for each sample. Just one little piece missing.... We want to know what we presented when. In most studies, we present stimuli that can be pictures, sounds or even videos. For the latter analysis, it is important to know at what point in our data we presented these stimuli.

Luckily there is a simple way we can achieve this. We can set a string that our callback function can access and include in our data. To make sure that our callback function can access this variable we will use the `global` keyword. This makes sure that we can read/modify a variable that exist outside of the function.

Thus each time the callback function will be run it will also have access to the trigger variable. We save the trigger to the `ev` variable and we set it back to an empty string `""` .

This means that we can set the trigger to whatever string we want and when we set it it will be picked up by the callback function.

```{python}
def gaze_data_callback(gaze_data):
    global trigger

    if len(trigger)==0:
        ev = ''
    else:
        ev = trigger
        trigger=[]
    
    # Extract the data we are interested in
    t  = gaze_data.system_time_stamp / 1000.0
    lx = gaze_data.left_eye.gaze_point.position_on_display_area[0] * winsize[0]
    ly = gaze_data.left_eye.gaze_point.position_on_display_area[1] * winsize[1]
    lp = gaze_data.left_eye.pupil.diameter
    lv = gaze_data.left_eye.gaze_point.validity
    rx = gaze_data.right_eye.gaze_point.position_on_display_area[0] * winsize[0]
    ry = gaze_data.right_eye.gaze_point.position_on_display_area[1] * winsize[1]
    rp = gaze_data.right_eye.pupil.diameter
    rv = gaze_data.right_eye.gaze_point.validity
    
    
trigger = ''

# Time passes
# when you present a stimulus you can set trigger to a string that will be captured by the callabck function

trigger = 'Presented Stimulus'
```

Perfect now we have a way to access the data from the eye-tracker and to account for what we are presenting to out participant.

## Save the data

If, if you've been paying attention, you might've noticed that we get the data in our callback function but don't actually save it anywhere. So how to save them? There are two main approaches we can use:

1.  We could have a saving function inside our callback that could append the new data to a .csv each time the callback is called.

2.  We could append the data to a list. Once the experiment is finished we could save our data.

These two approaches have however some weaknesses. The first could slow down the callback function if our pc is not performing or if we are sampling at a very high sampling rate. The second is potentially faster, but if anything happens thought the study that makes python crash ( trust me, it can happen.....) you would loose all your data.

What is the solution you ask? A mixed approach!!!!!!!\
We can store our data in a list and save it during the less important parts of the study, for example the Inter Stimulus Interval ( the time between a trial and another). So let's write a function to do exactly that.

Lets first create an empty list that we will fill with out data from the callback function. As before, we make sure that our callback function can access this list and append the new data we will use the `global` keyword.

```{python}

# Create an empty list we will append our data to
gaze_data_buffer = []

# This will be called every time there is new gaze data
def gaze_data_callback(gaze_data):
    global gaze_data_buffer
    global trigger

    if len(trigger)==0:
        ev = ''
    else:
        ev = trigger
        trigger=[]
        
    # Extract the data we are interested in
    t  = gaze_data.system_time_stamp / 1000.0
    lx = gaze_data.left_eye.gaze_point.position_on_display_area[0] * winsize[0]
    ly = gaze_data.left_eye.gaze_point.position_on_display_area[1] * winsize[1]
    lp = gaze_data.left_eye.pupil.diameter
    lv = gaze_data.left_eye.gaze_point.validity
    rx = gaze_data.right_eye.gaze_point.position_on_display_area[0] * winsize[0]
    ry = gaze_data.right_eye.gaze_point.position_on_display_area[1] * winsize[1]
    rp = gaze_data.right_eye.pupil.diameter
    rv = gaze_data.right_eye.gaze_point.validity
        
    # Add gaze data to the buffer 
    gaze_data_buffer.append((t,lx,ly,lp,lv,rx,ry,rp,rv,ev))
```

Now the gaze_data_buffer will be filled with the data we extract. Let's save this list then.

We will first make a copy of the list and then clear it. This way we have our data and the original list is empty and can be filled with new data.

After creating a copy, we use `pandas` to transform the list into a data frame and save it to a csv file. Using `mode = 'a'` we tell pandas to append the new data to the existing .csv, if this is the first time and the .csv does not yet exist, pandas will create the csv instead.

```{python}
def write_buffer_to_file(buffer, output_path):

    # Make a copy of the buffer and clear it
    buffer_copy = buffer[:]
    buffer.clear()
    
    # Define column names for the dataframe
    columns = ['time', 'L_X', 'L_Y', 'L_P', 'L_V', 
               'R_X', 'R_Y', 'R_P', 'R_V', 'Event']

    # Convert buffer to DataFrame
    out = pd.DataFrame(buffer_copy, columns=columns)
    
    # Check if the file exists
    file_exists = not os.path.isfile(output_path)
    
    # Write the DataFrame to an HDF5 file
    out.to_csv(output_path, mode='a', index =False, header = file_exists)
```

# Create the actual experiment

Now we have two function, one to access and append the data to a list, and the second to save the data to a csv. Let's see now how to include this functions in our study.

## Short recap of the paradigm

As we already mentioned, we will use the experimental design that we created in [Getting started with Psychopy](GettingStartedWithPsychopy.qmd) as a base and we will add things to it to make it an eye-tracking study. If you don't remember the paradigm please give it a rapid look as we will not go into much detail about each specific part of it.

Here a very short summary of what the design was:

After a fixation cross two shapes can be presented: a circle or a square. The circle indicates that a reward will appear on the right of the screen while the square predicts the appearance of an empty cloud on the left.

## Combine things

Let's try to build together the experiment then.

### Import and fucntions

To start let's import the libraries and define the two functions that we create before

```{python}
import os
import glob
import pandas as pd

# Import some libraries from PsychoPy
from psychopy import core, event, visual, prefs
prefs.hardware['audioLib'] = ['PTB']
from psychopy import sound

import tobii_research as tr


#%% Functions

# This will be called every time there is new gaze data
def gaze_data_callback(gaze_data):
    global trigger
    global gaze_data_buffer
    global winsize

    if len(trigger)==0:
        ev = ''
    else:
        ev = trigger
        trigger=[]
    
    # Extract the data we are interested in
    t  = gaze_data.system_time_stamp / 1000.0
    lx = gaze_data.left_eye.gaze_point.position_on_display_area[0] * winsize[0]
    ly = gaze_data.left_eye.gaze_point.position_on_display_area[1] * winsize[1]
    lp = gaze_data.left_eye.pupil.diameter
    lv = gaze_data.left_eye.gaze_point.validity
    rx = gaze_data.right_eye.gaze_point.position_on_display_area[0] * winsize[0]
    ry = gaze_data.right_eye.gaze_point.position_on_display_area[1] * winsize[1]
    rp = gaze_data.right_eye.pupil.diameter
    rv = gaze_data.right_eye.gaze_point.validity
        
    # Add gaze data to the buffer 
    gaze_data_buffer.append((t,lx,ly,lp,lv,rx,ry,rp,rv,ev))
    
        
def write_buffer_to_file(buffer, output_path):

    # Make a copy of the buffer and clear it
    buffer_copy = buffer[:]
    buffer.clear()
    
    # Define column names
    columns = ['time', 'L_X', 'L_Y', 'L_P', 'L_V', 
               'R_X', 'R_Y', 'R_P', 'R_V', 'Event']

    # Convert buffer to DataFrame
    out = pd.DataFrame(buffer_copy, columns=columns)
    
    # Check if the file exists
    file_exists = not os.path.isfile(output_path)
    
    # Write the DataFrame to an HDF5 file
    out.to_csv(output_path, mode='a', index =False, header = file_exists)
```

### Load the stimuli

Now we are going to set a few settings, such as the screen size, create a psychpy window, load the stimuli and then prepare the trial definition. This is exactly the same as we did in the previous Psychopy tutorial.

```{python}
#%% Load and prepare stimuli

# Winsize
winsize = (1920, 1080)

# create a window
win = visual.Window(size = winsize,fullscr=True, units="pix", pos =(0,30), screen=1)

# Load images
fixation = visual.ImageStim(win, image='EXP\\getting_started_psychopy\\fixation.png', size = (200, 200))
circle   = visual.ImageStim(win, image='EXP\\getting_started_psychopy\\circle.png', size = (200, 200))
square   = visual.ImageStim(win, image='EXP\\getting_started_psychopy\\square.png', size = (200, 200))
winning   = visual.ImageStim(win, image='EXP\\getting_started_psychopy\\winning.png', size = (200, 200), pos=(560,0))
loosing  = visual.ImageStim(win, image='EXP\\getting_started_psychopy\\loosing.png', size = (200, 200), pos=(-560,0))

# Load sound
winning_sound = sound.Sound('EXP\\getting_started_psychopy\\winning.wav')
losing_sound = sound.Sound('EXP\\getting_started_psychopy\\loosing.wav')

# List of stimuli
cues = [circle, square] # put both cues in a list
rewards = [winning, loosing] # put both rewards in a list
sounds = [winning_sound,losing_sound] # put both sounds in a list

# Create list of trials in which 0 means winning and 1 means losing
Trials = [0, 1, 0, 0, 1, 0, 1, 1, 0, 1 ]
```

### Start recording

Perfect now that we have everything we will look for the eye-trackers connected to the computer and select the first one that we find. One we have selected it we will launch our callback function to start collecting data.

```{python}
#%% Record the data

# Find all connected eye trackers
found_eyetrackers = tr.find_all_eyetrackers()

# We will just use the first one
Eyetracker = found_eyetrackers[0]

#Start recording
Eyetracker.subscribe_to(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
```

### Present our stimuli

The eye-tracking is running! Let's show our participant something!

As you can see below, after each time we flip our window (remember: flipping means we actually show what we drew), we set the trigger variable to a string that identifies the specific stimulus we are presenting. This will be picked up our callback function.

```{python}

for trial in Trials:

    ### Present the fixation
    win.flip() # we flip to clean the window

        
    fixation.draw()
    win.flip()
    trigger = 'Fixation'
    core.wait(1)  # wait for 1 second


    ### Present the cue
    cues[trial].draw()
    win.flip()
    if trial ==0:
        trigger = 'Circle'
    else:
        trigger = 'Square'

    core.wait(3)  # wait for 3 seconds
    win.flip()

    ### Wait for saccadic latencty
    core.wait(0.75)

    ### Present the reward
    rewards[trial].draw()
    win.flip()

    if trial ==0:
        trigger = 'Reward'
    else:
        trigger = 'NoReward'
        
    sounds[trial].play()
    
    core.wait(2)  # wait for 1 second
    win.flip()    # we re-flip at the end to clean the window
```

As we said before in [Save the data], it is best to save the data thought our study to avoid any potential data loss. And it is better to do this when there are things of minor interest, such as an ISI. So now we will modify a little our ISI presentation in comparison to the previous psychopy design.

We will create a psychopy clock. Once the clock is initiated it will start to track time and we can access how much time passed from it initiation by running `.getTime()`. Our aim here is to save our data, and this will take some time depending on how much data we have collected. Since the time that it will take will be variable we will be simply check how much time has passed after saving the data and wait (using the while: pass code) until 1 second has fully passed. This will ensure that we will wait for 1 second in total considering the saving of the data.

```{python}

    ### ISI
    clock = core.Clock()
    write_buffer_to_file(gaze_data_buffer, 'DATA\\RAW\\'+ Sub +'.csv')
    print(clock.getTime())
    while clock.getTime() < 1:
        pass
```

```{python}
win.close()
Eyetracker.unsubscribe_from(tr.EYETRACKER_GAZE_DATA, gaze_data_callback)
```
