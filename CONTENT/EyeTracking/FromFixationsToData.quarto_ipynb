{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"From fixations to measures\"\n",
        "date: \"09/07/2024\"\n",
        "execute:\n",
        "  eval: true\n",
        "\n",
        "jupyter:\n",
        "  kernel: \"python3\"\n",
        "\n",
        "author-meta: \"Tommaso Ghilardi\"\n",
        "description-meta: \"Learn how to extract different eye-tracking measures from the collected data\"\n",
        "keywords: \"Python, latency, saccadic-latency, looking time, eye-tracking, tobii, experimental psychology, tutorial, experiment, DevStart, developmental science\"\n",
        "categories:\n",
        "  - Eye-tracking\n",
        "  - Python\n",
        "---\n",
        "\n",
        "\n",
        "In the previous two tutorials we [collected some eye-tracking data](/CONTENT/EyeTracking/CreateAnEyetrackingExperiment.qmd) and then we [used I2MC to extract the fixations](/CONTENT/EyeTracking/I2MC_tutorial.qmd) from that data. Let's load the data we recorded and pre-processed in the previous tutorial. We will import some libraries and read the raw data and the output from I2MC.\n"
      ],
      "id": "f382a8bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "#%% Settings\n",
        "\n",
        "# Screen resolution\n",
        "screensize = (1920, 1080) \n",
        "\n",
        "\n",
        "#%% Read and prepare data\n",
        "\n",
        "# The fixation data extracted from I2MC\n",
        "Fixations = pd.read_csv('..\\\\..\\\\resources\\\\FromFixationToData\\\\DATA\\\\i2mc_output\\\\Adult1\\\\Adult1.csv')\n",
        "\n",
        "# The original RAW data\n",
        "Raw_data = pd.read_csv('..\\\\..\\\\resources\\\\FromFixationToData\\\\DATA\\\\RAW\\\\Adult1.csv')"
      ],
      "id": "a89be097",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What can we do with just the raw data and the fixations? Not much I am afraid. But we can use these fixations to extract some more meaningful indexes.\n",
        "\n",
        "In this tutorial, we will look at how to extract two variables from our paradigm:\n",
        "\n",
        "-   **Saccadic latency:** how quickly our participant looked at the correct location. This includes checking whether the participant could anticipate the stimulus appearance. In our paradigm, we will look at how fast our participant looked at the target location (left: NoReward, right: Reward).\n",
        "\n",
        "-   **Looking time:** how long our participant looked at certain locations on the screen. In our case, we will look at how long our participant looked at either target location (left: NoReward, right: Reward) on each trial.\n",
        "\n",
        "So what do these two measures have in common? *pregnant pause for you to answer* EXACTLY!!! They are both clearly related to the position of our stimuli. For this reason, it is important to define Areas Of Interest (AOIs) on the screen (for example, the locations of the targets). Defining AOIs will allow us to check, for each single fixation, whether it happened in an area that we are interested in.\n",
        "\n",
        "# Areas Of Interest\n",
        "\n",
        "## Define AOIs\n",
        "\n",
        "Let's define AOIs. We will define two squares around the target locations. To do this, we can simply pass two coordinates for each AOI: the lower left corner and the upper right corner of an imaginary square.\n",
        "\n",
        "An important point to understand is that tobii and Psychopy use two different coordinate systems:\n",
        "\n",
        "-   Psychopy has its origin (0,0) in the centre of the window/screen by default.\n",
        "\n",
        "-   Tobii reports data with its origin (0,0) in the lower left corner.\n",
        "\n",
        "This inconsistency is not a problem per se, but we need to take it into account when defining the AOIs. Let's try to define the AOIs:\n"
      ],
      "id": "88091c5b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Screen resolution\n",
        "screensize = (1920, 1080) \n",
        "\n",
        "# Define the variable realted to AOIs and target position\n",
        "dimension_of_AOI = 600/2  #the dimension of the AOIs, divided by 2\n",
        "Target_position = 500 #the position of the targets relative to the centre (e.g., 500 pixels on the right from the centre)\n",
        "\n",
        "# Create areas of intescreensizet\n",
        "AOI1 =[[screensize[0]/2 - Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 - Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n",
        "\n",
        "AOI2 =[[screensize[0]/2 + Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 + Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n",
        "\n",
        "AOIs = [AOI1, AOI2]"
      ],
      "id": "e2f272e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nice!! This step is essential. We have created two AOIs. We will use them to define whether each fixation of our participant was within either of these two AOIs. Let's get a better idea by just plotting these two AOIs and two random points `(600, 500)` and `(1400,1000)`.\n"
      ],
      "id": "8537e010"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: \"center\"\n",
        "#| code-fold: true\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Create a figure\n",
        "fig, ax = plt.subplots(1, figsize=(8,4.4))\n",
        "\n",
        "# Set the limits of the plot\n",
        "ax.set_xlim(0, 1920)\n",
        "ax.set_ylim(0, 1080)\n",
        "\n",
        "# Define the colors for the rectangles\n",
        "colors = ['#46AEB9', '#C7D629']\n",
        "\n",
        "# Create a rectangle for each area of interest and add it to the plot\n",
        "for i, (bottom_left, top_right) in enumerate(AOIs):\n",
        "    width = top_right[0] - bottom_left[0]\n",
        "    height = top_right[1] - bottom_left[1]\n",
        "    rectangle = patches.Rectangle(bottom_left, width, height, linewidth=2, edgecolor='k', facecolor=colors[i])\n",
        "    ax.add_patch(rectangle)\n",
        "\n",
        "ax.plot(600,500,marker='o', markersize=8, color='green')    \n",
        "ax.plot(1400,1000,marker='o', markersize=8, color='red')    \n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "14957273",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Points in AOIs\n",
        "\n",
        "As you can see, we are plotting the two AOIs and two points. One falls into one of them and the other doesn't. But how can we get Python to tell us if a point falls within one of our AOIs?\n",
        "\n",
        "We can check whether the (x, y) coordinates of the point are within the x and y coordinates of the left bottom and top right corners of the AOI.\n",
        "\n",
        "![](/images/FromDataToMeasures/Squares.jpg){fig-align=\"center\" width=\"192\"}\n",
        "\n",
        "So imagine we have a point: `point` and an area: `area`, we can check if the point falls inside the area by:\n"
      ],
      "id": "b5a6b394"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "# Extract bottom left and top right points\n",
        "bottom_left, top_right = area\n",
        "\n",
        "# Extract the x and y of each point\n",
        "bottom_x, bottom_y = bottom_left\n",
        "top_x, top_y = top_right\n",
        "\n",
        "# Extract the x and y of our point of interest\n",
        "x, y = point\n",
        "\n",
        "# Check if the point is in the area\n",
        "bottom_x <= x <= top_x and bottom_y <= y <= top_y"
      ],
      "id": "a16138cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perfect, this will return True if the point falls inside the area and False if it falls outside. Since we have two AOIs and not just one, we want to make things a bit fancier. We will create a function that checks if a point falls within a list of areas, and tells us which area it falls in.\n",
        "\n",
        "We will run the code above in a loop using `enumerate`. This extracts two elements to our loop: the index of the element and the element itself. In our case the index of the area and the area itself. This is very useful as we can then use both of these two pieces of information. We will use the actual area to check if our points fall into it. Then, if it does, we will return the index of that area. Conversely, if the point doesn't fall in any area the function will return -1.\n"
      ],
      "id": "c43ffa86"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We define a function that simply takes the a point and a list of areas.\n",
        "# This function checks in which area this point is and return the index\n",
        "# of the area. If the point is in no area it returns -1\n",
        "def find_area_for_point(point, areas):\n",
        "\n",
        "    for i, area in enumerate(areas):\n",
        "        # Extract bottom left and top right points\n",
        "        bottom_left, top_right = area\n",
        "        \n",
        "        # Extract the x and y of each point\n",
        "        bottom_x, bottom_y = bottom_left\n",
        "        top_x, top_y = top_right\n",
        "        \n",
        "        # Extract the x and y of our point of interest\n",
        "        x, y = point\n",
        "        \n",
        "        # Check if the point is in the area\n",
        "        if bottom_x <= x <= top_x and bottom_y <= y <= top_y :\n",
        "            return(i)\n",
        "    return(-1)"
      ],
      "id": "97a25eb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have a cool function to check whether a point falls into any of our AOIs. We can use this function to filter the fixations that are in the AOIs: These are the only ones we care about.\n",
        "\n",
        "# Time Of Interest\n",
        "\n",
        "Now that we've figured out how to select fixations that fall within our areas of interest, it's time to consider another important factor: Time. Our experiment involves presenting a variety of stimuli, including fixation crosses, cues, and rewards. , we're not interested in analyzing the entire experiment. Instead, we focus on specific events.\n",
        "\n",
        "Let's take a look at the design image. What we are interest in is the last part of the target presentation.\n",
        "\n",
        "![](/images/FromDataToMeasures/DesignSelection.jpg){fig-align=\"center\" width=\"495\"}\n",
        "\n",
        "In this case, our attention is on the target window. We're going to establish a time window that begins 750ms before the target appears and continues for 2000ms after its pentation. Indeed, both **Saccadic latency** and **Lookign time** occur within this time window, while we don't really care about where the participant is looking during other phases of the task.\n",
        "\n",
        "Let's start by finding the moment in which the target appeared:\n"
      ],
      "id": "8a95df83"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Let's find the time we presented a reward or no reward\n",
        "Targets = Raw_data.loc[(Raw_data['Event'] == 'Reward') | (Raw_data['Event'] == 'NoReward'), ['time', 'Event']].values"
      ],
      "id": "6c475271",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having identified the moments when the targets were presented, we can now establish a time window around each of these instances. To accomplish this, we will iterate over the identified times and select all the fixations that occur within the defined window. To make things clearer, we're going to add two new columns to our fixation dataframe: `Event` and `Event_trial`. These will help us know which event each fixation is linked to, and which specific trial it belongs to. Plus, we're going to add another column called `Onset` to the fixations dataframe. This will let us store the onset times of specific events, making our analysis down the line a whole lot simpler.\n"
      ],
      "id": "8a3a319f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find the fixations that we care about\n",
        "pre  = -750\n",
        "post = 400\n",
        "\n",
        "for i,c in enumerate(Targets):\n",
        "    \n",
        "    # Find which row meets our conditions\n",
        "    mask = (Fixations['startT'] >= c[0]+pre) & (Fixations['startT'] < c[0]+post)\n",
        "    \n",
        "    # Fill the rows with have found with more info\n",
        "    Fixations.loc[mask, 'Event'] = c[1]\n",
        "    Fixations.loc[mask, 'Event_trial'] = i\n",
        "    Fixations.loc[mask, 'Onset'] =  c[0]"
      ],
      "id": "37381023",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our Fixations dataframe is now chock-full of event-related info. But, there's a catch. The fixations that took place at times other than during the target presentation are still hanging around in the dataframe. And they're filled with NANs in the new columns we just created.\n",
        "\n",
        "![](/images/FromDataToMeasures/CorrectFixations.jpg){fig-align=\"center\" width=\"416\"}\n",
        "\n",
        "We can use this to our advantage and filter all the NANs out:\n"
      ],
      "id": "3ee9b812"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We can drop the NANs to have only the fixations that interest us!!!!\n",
        "Target_fixations = Fixations[Fixations['Event'].notna()].reset_index(drop = True)"
      ],
      "id": "091679da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Put things together\n",
        "\n",
        "Now we have selected our fixations based on the events. But we also need to filter the fixations based on the AOIs. If only we had some functions to do so.... Oh wait, we actually just created them!! Let's make use of them!!\n",
        "\n",
        "As a first step, we will add a new column to our Target_fixations dataframe containing the AOIs we defined together before. Thus, each row of this column will tell us which AOIs we should check. We will also add a new column called `Looked_AOI` where we will store the indexes of which AOI the fixation fell into.\n",
        "\n",
        "::: callout-important\n",
        "Just a heads up: our study design is pretty straightforward with only two stable Areas of Interest (AOIs). But if you're dealing with multiple or moving AOIs, you've got options. You can add them to each row of the dataframe, depending on the event or trial. This way, you get more control over which area to inspect at any given moment of the study. It's all about flexibility and precision!\n",
        ":::\n"
      ],
      "id": "203f7fbe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Target_fixations['AOIs'] = [AOIs]* len(Target_fixations)\n",
        "Target_fixations['Looked_AOI'] = np.nan"
      ],
      "id": "a78f9ca3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a column with the AOIs in our Target_fixations dataframe, we can run our function `find_area_for_point()` to check in which AOI each fixation falls.\n"
      ],
      "id": "7a8b383d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We run the function  for each row. We pass each xpos and ypos to the function\n",
        "# toghether with the areas\n",
        "for row in range(len(Target_fixations)):\n",
        "    \n",
        "    Point = Target_fixations.loc[row, ['xpos', 'ypos']].values\n",
        "    Areas = Target_fixations.loc[row, 'AOIs']\n",
        "    \n",
        "    Target_fixations.loc[row, 'Looked_AOI'] = find_area_for_point(Point, Areas)"
      ],
      "id": "9b5564df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perfect, we now have a dataframe that contains only the fixations of interest and tells us which AOI each fixation is in. Before we continue, let's remove the fixations that didn't fall in any AOI (if you remember or the function assigns -1 if the fixation is outside any AOI):\n"
      ],
      "id": "8373198e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Filter for AOI of interest\n",
        "Target_fixations = Target_fixations[Target_fixations['Looked_AOI'] != -1]"
      ],
      "id": "2144c802",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Saccadic latency\n",
        "\n",
        "As I mentioned at the beginning of this tutorial, one of the indices we want to extract is saccadic latency. Basically, this indicates how quickly our participants fixated on the correct target location.\n",
        "\n",
        "If we know where our participant was supposed to look, we can easily find the first fixation. Sounds simple, right?\n",
        "\n",
        "In our paradigm, the non-rewarding stimulus was always presented on the left (the first AOI we defined) and the rewarding stimulus was always presented on the right (the second AOI we defined). Thus we can add this information to our dataframe and then use it to filter out the wrong fixations:\n"
      ],
      "id": "14a91d03"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| warning: false\n",
        "# We define which is the correct AOI that the participant should have looked at.\n",
        "Target_fixations.loc[Target_fixations['Event'] == 'NoReward', 'Correct_Aoi'] = 0\n",
        "Target_fixations.loc[Target_fixations['Event'] == 'Reward'  , 'Correct_Aoi'] = 1\n",
        "\n",
        "# We select only the correct fixations\n",
        "Correct_Target_fixations = Target_fixations.loc[Target_fixations['Correct_Aoi'] == Target_fixations['Looked_AOI'],]"
      ],
      "id": "0505b908",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can finally extract the saccadic latency by simply subtracting from the onset of the fixations (`startT`) the event `Onset`:\n"
      ],
      "id": "93b42b01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Correct_Target_fixations['Latency'] = Correct_Target_fixations['startT'] - Correct_Target_fixations['Onset']"
      ],
      "id": "62ed1a23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VoilÃ¡!! as simple as this!!! Now our `Latency` column will contain the onset of the fixations in relation to the target presentation.\n",
        "\n",
        "::: callout-note\n",
        "Saccadic latency can be negative!!. This indicates that participants were able to predict the location of the stimulus and directed their gaze to it in anticipation. Typically, this is the primary use of saccadic latency - it serves as a tool to assess participants' expectations in relation to our design.\n",
        ":::\n",
        "\n",
        "## First fixation\n",
        "\n",
        "We have all these latency values, but we only want the first/fastest of each trial. How can we extract this information easily? We will use groupby. Groupby allows us to perform specific functions/commands on grouped sections of a data frame.\n",
        "\n",
        "Here we will groupby by Events and Event_trials and for each of these grouped pieces of dataframe we will extract the smallest (`min()`) value of latency.\n"
      ],
      "id": "9b4db8e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We extract the first fixation of our dataframe for each event\n",
        "SaccadicLatency = Correct_Target_fixations.groupby(['Event', 'Event_trial'])['Latency'].min().reset_index()"
      ],
      "id": "53b3f69e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we have our **Saccadic latency**!!!\n",
        "\n",
        "Once our dataset is ready, we might want to visualise the data. For example, we can plot how saccadic latency changes across trials with seaborn:\n"
      ],
      "id": "d0eac528"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: \"center\"\n",
        "import seaborn as sns # import seaborn\n",
        "plt.figure()\n",
        "\n",
        "# Scatterplot\n",
        "ax = sns.scatterplot(data=SaccadicLatency, x=\"Event_trial\", y=\"Latency\", hue='Event')\n",
        "\n",
        "# Place the legend \n",
        "sns.move_legend(ax,loc=\"upper left\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "730a876f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Looking time\n",
        "\n",
        "While our paradigm was designed with saccadic latency in mind, for the purposes of this tutorial we will also be looking at the extraction of looking time. Looking time is a measure that tells us how much our participant was looking in either of the two AOIs at each trial.\n",
        "\n",
        "We have already extracted all the information we need, we just need to do the final steps. We will again use groupby to group our dataframe by `Event`, `Event_trial` and `Looked_AOI`. For each of the grouped dataframes, we will extract the `sum()` of each fixation duration. This will tell us how much the participant looked at each of the two AOIs for each trial.\n"
      ],
      "id": "8571ecc7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Using groupby we can extract the sum of the duration of the fixation for each reward and trial\n",
        "LookingTime = Target_fixations.groupby(['Event', 'Event_trial', 'Looked_AOI'], as_index=False)['dur'].sum()"
      ],
      "id": "f8f4cdb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, we can now visualize the data. For example, we can plot whether looking time to rewarding vs. non-rewarding stimuli:\n"
      ],
      "id": "7bbefa2e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-align: \"center\"\n",
        "plt.figure()\n",
        "\n",
        "# Barplot\n",
        "ax = sns.barplot(data=LookingTime, y=\"dur\", hue = 'Event', x = 'Event')\n",
        "ax.set_ylabel(\"Duration\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "962a46ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# END!!\n",
        "\n",
        "Well done!! we have successfully extracted both saccadic latency and looking time from our data. Remember that it is just a simple tutorial based on an even simpler design. However, if you got to the end and you have understood all the steps and what they mean, I am sure you can apply this knowledge to your study as well. If you have any questions or if something is not clear, feel free to send us an email!!\\\n",
        "\\\n",
        "Here below the entire script!!\\\n",
        "\n",
        "``` python\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "#%% Fucntions\n",
        "\n",
        "# We define a function that simply takes the a point and a list of areas.\n",
        "# This function checks in which area this point is and return the index\n",
        "# of the area. If the point is in no area it returns -1\n",
        "def find_area_for_point(point, areas):\n",
        "\n",
        "    for i, area in enumerate(areas):\n",
        "        # Extract bottom left and top right points\n",
        "        bottom_left, top_right = area\n",
        "        \n",
        "        # Extract the x and y of each point\n",
        "        bottom_x, bottom_y = bottom_left\n",
        "        top_x, top_y = top_right\n",
        "        \n",
        "        # Extract the x and y of our point of interest\n",
        "        x, y = point\n",
        "        \n",
        "        # Check if the point is in the area\n",
        "        if bottom_x <= x <= top_x and bottom_y <= y <= top_y :\n",
        "            return(i)\n",
        "    return(-1)\n",
        "\n",
        "\n",
        "\n",
        "#%% Settings and reading data\n",
        "\n",
        "# The fixation data extracted from I2MC\n",
        "Fixations = pd.read_csv('..\\\\..\\\\resources\\\\FromFixationToData\\\\DATA\\\\i2mc_output\\\\Adult1\\\\Adult1.csv')\n",
        "\n",
        "# The original RAW data\n",
        "Raw_data = pd.read_csv('..\\\\..\\\\resources\\\\FromFixationToData\\\\DATA\\\\RAW\\\\Adult1.csv')\n",
        "\n",
        "\n",
        "\n",
        "#%% Areas of interest\n",
        "\n",
        "# Screen resolution\n",
        "screensize = (1920, 1080) \n",
        "\n",
        "# Define the variable realted to AOIs and target position\n",
        "dimension_of_AOI = 600/2  #the dimension of the AOIs, divided by 2\n",
        "Target_position = 500 #the position of the targets relative to the centre (e.g., 500 pixels on the right from the centre)\n",
        "\n",
        "# Create areas of intescreensizet\n",
        "AOI1 =[[screensize[0]/2 - Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 - Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n",
        "\n",
        "AOI2 =[[screensize[0]/2 + Target_position - dimension_of_AOI, screensize[1]/2-dimension_of_AOI], [screensize[0]/2 + Target_position + dimension_of_AOI, screensize[1]/2 + dimension_of_AOI]]\n",
        "\n",
        "AOIs = [AOI1, AOI2]\n",
        "\n",
        "\n",
        "\n",
        "#%% Time of interest\n",
        "\n",
        "# Let's find the time we presented a reward or no reward\n",
        "Targets = Raw_data.loc[(Raw_data['Event'] == 'Reward') | (Raw_data['Event'] == 'NoReward'), ['time', 'Event']].values\n",
        "\n",
        "# Find the fixations that we care about\n",
        "pre  = -750\n",
        "post = 400\n",
        "\n",
        "for i,c in enumerate(Targets):\n",
        "    \n",
        "    # Find which row meets our conditions\n",
        "    mask = (Fixations['startT'] >= c[0]+pre) & (Fixations['startT'] < c[0]+post)\n",
        "    \n",
        "    # Fill the rows with have found with more info\n",
        "    Fixations.loc[mask, 'Event'] = c[1]\n",
        "    Fixations.loc[mask, 'Event_trial'] = i\n",
        "    Fixations.loc[mask, 'Onset'] =  c[0]\n",
        "    \n",
        "# We can drop the NANs to have only the fixations that interest us!!!!\n",
        "Target_fixations = Fixations[Fixations['Event'].notna()].reset_index(drop = True)\n",
        "\n",
        "\n",
        "\n",
        "#%% Put things together\n",
        "\n",
        "# Add the AOIs to dataframe\n",
        "Target_fixations['AOIs'] = [AOIs]* len(Target_fixations)\n",
        "Target_fixations['Looked_AOI'] = np.nan\n",
        "\n",
        "# We run the function  for each row. We pass each xpos and ypos to the function\n",
        "# toghether with the areas\n",
        "for row in range(len(Target_fixations)):\n",
        "    \n",
        "    Point = Target_fixations.loc[row, ['xpos', 'ypos']].values\n",
        "    Areas = Target_fixations.loc[row, 'AOIs']\n",
        "    \n",
        "    Target_fixations.loc[row, 'Looked_AOI'] = find_area_for_point(Point, Areas)\n",
        "    \n",
        "# Filter for AOI of interest\n",
        "Target_fixations = Target_fixations[Target_fixations['Looked_AOI'] != -1]\n",
        "\n",
        "\n",
        "\n",
        "#%% Saccadic Latency\n",
        "\n",
        "# We define which is the correct AOI that the participant should have looked at.\n",
        "Target_fixations.loc[Target_fixations['Event'] == 'NoReward', 'Correct_Aoi'] = 0\n",
        "Target_fixations.loc[Target_fixations['Event'] == 'Reward'  , 'Correct_Aoi'] = 1\n",
        "\n",
        "# We select only the correct fixations\n",
        "Correct_Target_fixations = Target_fixations[Target_fixations['Correct_Aoi'] == Target_fixations['Looked_AOI']]\n",
        "\n",
        "# Keep only the fixation to the correct AOI\n",
        "Correct_Target_fixations['Latency'] = Correct_Target_fixations['Onset'] - Correct_Target_fixations['startT']\n",
        "\n",
        "# We extract the first fixation of our dataframe for each event\n",
        "SaccadicLatency = Correct_Target_fixations.groupby(['Event', 'Event_trial'])['Latency'].min().reset_index()\n",
        "\n",
        "### PLOT\n",
        "plt.figure()\n",
        "\n",
        "# Scatterplot\n",
        "ax = sns.scatterplot(data=SaccadicLatency, x=\"Event_trial\", y=\"Latency\", hue='Event')\n",
        "\n",
        "# Place the legend \n",
        "sns.move_legend(ax,loc=\"upper left\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#%% Looking time\n",
        "\n",
        "# Using groupby we can extract the sum of the duration of the fixation for each reward and trial\n",
        "LookingTime = Target_fixations.groupby(['Event', 'Event_trial', 'Looked_AOI'], as_index=False)['dur'].sum()\n",
        "\n",
        "### PLOT\n",
        "plt.figure()\n",
        "\n",
        "# Barplot\n",
        "ax = sns.barplot(data=LookingTime, x=\"Event\", y=\"dur\", hue='Event')\n",
        "\n",
        "# Place the legend \n",
        "sns.move_legend(ax,loc=\"upper center\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "```"
      ],
      "id": "7f0af888"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}