---
title: Create an eye-tracking experiment
execute:
  eval: false

pagetitle: Create an eye-tracking experiment
author-meta: Tommaso Ghilardi
description-meta: Learn how to record eyetracking data in your psychopy experiment using Tobii SDK and psychopy_tobii_infant.
keywords: PsychoPy, Python, eye-tracking, psychopy_tobii_infant, tobii, experimental psychology, tutorial, experiment, DevStart, developmental science
---

This page will show you how to collect eye-tracking data in a simple psychopy paradigm. We will use the same paradigm that we built together in the [Getting started with Psychopy](GettingStartedWithPsychopy.qmd) tutorial. If you have not done that tutorial yet, please go through it first.

::: callout-caution
## Tobii eye-tracker

Note that this tutorial is specific for using **Tobii eye-trackers**. The general steps and idea are obviously applicable to other eye-trackers, but the specific code and packages vary depending on the device.
:::

## How to connect to the eye-tracker

We have different options to use our Tobii eye tracker. One option is to use the software that Tobii provides. However, this software is very expensive and sometimes not flexible enough for all the studies. We prefer to use the **SDK** that Tobii provides.

An **SDK** is a collection of tools and programs for developing applications for a specific platform or device. We will use the **Python Tobii SDK** that lets us easily find and get data from our Tobii eye tracker.

To install the Python Tobii SDK, we can run this command:

``` bash
pip install tobii_research
```

Great! We have installed the Tobii SDK. However, using the SDK is not very easy. But don't worry! We have a solution for you. We can use [Psychopy_tobii_infant](https://github.com/yh-luo/psychopy_tobii_infant), a wrapper around the Tobii SDK that is specially designed for running infant-friendly studies. This code collection allows us to use the Tobii SDK with the Psychopy interface.

To use Psychopy_tobii_infant, you need to go to this GitHub page: <https://github.com/yh-luo/psychopy_tobii_infant>. On this page, you can click on ***\<\>Code*** and then on ***Download ZIP*** as shown below:

![](images/CreateAnEyetrackingExperiment/DowloadPsychopyTobiiInfant.jpg){fig-align="center" width="545"}

Perfect!! Now that we have downloaded the code as a zip file we need to:

-   extract the file

-   identify the folder *'psychopy_tobii_infant'*

-   copy this folder in the same location of your eye-tracking experiment script

You should end up like with something like this:\
![](images/CreateAnEyetrackingExperiment/FinalConfTobiiInfant.png)

**Now we are all set and ready to go !!!!!!!!!!**

## Short recap of the paradigm

As we alredy mentioned, we will use the experiemntal dsign that we created in [Getting started with Psychopy](GettingStartedWithPsychopy.qmd) as a base and we will add things to it to make it an eye-tracking study. Before getting started, let's review the design.

After a fixation cross two shapes can be presented: a circle or a square. The circle indicates that a reward will appear on the right of the screen while the square predicts the appearance of an empty cloud on the left.

![](images/GettingStartedWithPsychopy/Design.jpg){fig-align="center"}

Here the code we wrote together to build this design.

```{python}
# Import some libraries from PsychoPy
from psychopy import visual
from psychopy import core
from psychopy import sound

# Let's define the path we will work with.
# in my case the stimuli that we will use are in here but you will have to adapt
# this variable to where you have downloaded the stimuli.
Path = r'C:\\Users\\tomma\\surfdrive - Ghilardi, T. (Tommaso)@surfdrive.surf.nl\\Documentation\\Working\\GettingStartedWithPsychopy\\'

# create a window
win = visual.Window(fullscr = True, units="pix")

# Load images
fixation = visual.ImageStim(win, image=Path + 'fixation.png', size = (100, 100))
circle   = visual.ImageStim(win, image=Path + 'circle.png', size = (100, 100))
square   = visual.ImageStim(win, image=Path + 'square.png', size = (100, 100))
winning   = visual.ImageStim(win, image=Path + 'winning.png', size = (100, 100), pos=(600,0))
loosing  = visual.ImageStim(win, image=Path + 'loosing.png', size = (100, 100), pos=(-600,0))

# Load sound
winning_sound = sound.Sound(Path + 'winning.wav')
losing_sound = sound.Sound(Path + 'loosing.wav')

# List of stimuli
cues = [circle, square] # put both cues in a list
rewards = [winning, loosing] # put both rewards in a list
sounds = [winning_sound,losing_sound] # put both sounds in a list


# Create list of trials in which 0 means winning and 1 means losing
Trials = [0, 1, 0, 0, 1, 0, 1, 1, 0, 1 ]


for trial in Trials:

    ### Present the fixation
    win.flip() # we flip to clean the window

    fixation.draw()
    win.flip()
    core.wait(1)  # wait for 1 second


    ### Present the cue
    cues[trial].draw()
    win.flip()
    core.wait(3)  # wait for 3 seconds


    ### Present the reward
    rewards[trial].draw()
    win.flip()
    sounds[trial].play()
    core.wait(2)  # wait for 1 second
    win.flip()    # we re-flip at the end to clean the window

    ### ISI
    core.wait(0.3) # add Inter Stimulus Interval to make exp more understandable

win.close()
```
